{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baldezo313/Artificial-Neural-Networks/blob/main/code/Binary_Classification_Bank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6knRRg50uNi"
      },
      "source": [
        "\n",
        "We need to train a model that predicts if a customer will leave the bank or not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya2ChmHe0XFq"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0jjbROfS8sr",
        "outputId": "9df306f5-cf5d-45ee-c5c3-ebe430bc7f2e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "9KbrEFZj096J",
        "outputId": "567d4691-5dc5-4860-8558-cd9b429db855"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/vatIAtech/DSTI/ANN/practical/Churn_Modelling.csv')\n",
        "#Kaggle database (source: https://www.kaggle.com/aakash50897/churn-modellingcsv?select=Churn_Modelling.csv)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-15df016e-3ad9-4d10-b644-251381c81958\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>Obijiaku</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>Johnstone</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>Liu</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>Sabbatini</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>Walker</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15df016e-3ad9-4d10-b644-251381c81958')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15df016e-3ad9-4d10-b644-251381c81958 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15df016e-3ad9-4d10-b644-251381c81958');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
              "0             1    15634602   Hargrave          619    France  Female   42   \n",
              "1             2    15647311       Hill          608     Spain  Female   41   \n",
              "2             3    15619304       Onio          502    France  Female   42   \n",
              "3             4    15701354       Boni          699    France  Female   39   \n",
              "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
              "...         ...         ...        ...          ...       ...     ...  ...   \n",
              "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
              "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
              "9997       9998    15584532        Liu          709    France  Female   36   \n",
              "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
              "9999      10000    15628319     Walker          792    France  Female   28   \n",
              "\n",
              "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0          2       0.00              1          1               1   \n",
              "1          1   83807.86              1          0               1   \n",
              "2          8  159660.80              3          1               0   \n",
              "3          1       0.00              2          0               0   \n",
              "4          2  125510.82              1          1               1   \n",
              "...      ...        ...            ...        ...             ...   \n",
              "9995       5       0.00              2          1               0   \n",
              "9996      10   57369.61              1          1               1   \n",
              "9997       7       0.00              1          0               1   \n",
              "9998       3   75075.31              2          1               0   \n",
              "9999       4  130142.79              1          1               0   \n",
              "\n",
              "      EstimatedSalary  Exited  \n",
              "0           101348.88       1  \n",
              "1           112542.58       0  \n",
              "2           113931.57       1  \n",
              "3            93826.63       0  \n",
              "4            79084.10       0  \n",
              "...               ...     ...  \n",
              "9995         96270.64       0  \n",
              "9996        101699.77       0  \n",
              "9997         42085.58       1  \n",
              "9998         92888.52       1  \n",
              "9999         38190.78       0  \n",
              "\n",
              "[10000 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vE91SQMHyXi",
        "outputId": "0142973e-d2b9-4f02-e7cc-5b3bbf903e16"
      },
      "source": [
        "print(dataset.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
            "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
            "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVECJ62mH3pY",
        "outputId": "5e3afd76-1da6-40ab-bf24-47b1bb7b4787"
      },
      "source": [
        "print(dataset.index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RangeIndex(start=0, stop=10000, step=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGuAUjvr4THk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720c7400-f90a-4a1a-8876-7fadc72ceca8"
      },
      "source": [
        "#Not all independent variables are important for the result (such as RowNumber, CustomerId)\n",
        "X = dataset.iloc[:, 3: 13].values\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
              "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
              "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
              "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
              "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V404Isjt5wCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436ed8c2-38ac-4255-d045-d2b5824c8cc6"
      },
      "source": [
        "#labels\n",
        "y = dataset.iloc[:, 13].values\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTvWAcpy6C_H",
        "outputId": "2b81d290-0c38-4363-b8bd-79fcdfe1d186"
      },
      "source": [
        "#Data encoding :\n",
        "#We have to encode categorical data (such as Geography and Gender)\n",
        "#ORDINAL ENCODING - way 1:\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X_ord_1 = dataset.iloc[:, 3: 13].values\n",
        "\n",
        "labelencoder_X = LabelEncoder() #instantiate an object of the class LabelEncoder\n",
        "X_ord_1[:, 1] = labelencoder_X.fit_transform(X_ord_1[:, 1]) #ordinal encoding for column 1\n",
        "\n",
        "X_ord_1[:, 2] = labelencoder_X.fit_transform(X_ord_1[:, 2]) #ordinal encoding for column 2\n",
        "\n",
        "X_ord_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 0, 0, ..., 1, 1, 101348.88],\n",
              "       [608, 2, 0, ..., 0, 1, 112542.58],\n",
              "       [502, 0, 0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 0, 0, ..., 0, 1, 42085.58],\n",
              "       [772, 1, 1, ..., 1, 0, 92888.52],\n",
              "       [792, 0, 0, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfBA7BYUjc-l",
        "outputId": "e097e8c7-8ed9-4e41-8ba6-7ae392416bcf"
      },
      "source": [
        "#ORDINAL ENCODING - way 2:  #bug - sets all values to zero!\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "X_ord_2 = dataset.iloc[:, 3: 13].values\n",
        "\n",
        "ordinal_encoder_1 = OrdinalEncoder()\n",
        "X_ord_2[:, 1] = ordinal_encoder_1.fit_transform([X_ord_2[:, 1]])\n",
        "X_ord_2[:, 2] = ordinal_encoder_1.fit_transform([X_ord_2[:, 2]])\n",
        "\n",
        "X_ord_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[619, 0.0, 0.0, ..., 1, 1, 101348.88],\n",
              "       [608, 0.0, 0.0, ..., 0, 1, 112542.58],\n",
              "       [502, 0.0, 0.0, ..., 1, 0, 113931.57],\n",
              "       ...,\n",
              "       [709, 0.0, 0.0, ..., 0, 1, 42085.58],\n",
              "       [772, 0.0, 0.0, ..., 1, 0, 92888.52],\n",
              "       [792, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1wMNx-Jn-Z0"
      },
      "source": [
        "X = X_ord_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "znjFEXDQ7Wfl",
        "outputId": "e1cf68dd-4c39-447d-dcc6-29eb835c5876"
      },
      "source": [
        "#ONE-HOT ENCODING :\n",
        "#Way 1 : using data values :\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import numpy as np\n",
        "\n",
        "ct = ColumnTransformer( #'encoder' is the name of the column transformer\n",
        "    [('encoder', OneHotEncoder(), [1])],    # The column numbers to be transformed (here is [1] but can be [0, 1, 3])\n",
        "    remainder='passthrough'                         # Leave the rest of the columns untouched\n",
        ")\n",
        "\n",
        "X = np.array(ct.fit_transform(X), dtype=np.int) #Note: The X matrix should be ordinally encoded (with ordinal encoding applied to it)\n",
        "df = pd.DataFrame(X)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f97da3a1-4925-440c-829d-ebccc70cebc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>619</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>502</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>850</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>771</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>516</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>709</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>772</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>792</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f97da3a1-4925-440c-829d-ebccc70cebc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f97da3a1-4925-440c-829d-ebccc70cebc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f97da3a1-4925-440c-829d-ebccc70cebc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      0   1   2    3   4   5   6       7   8   9   10      11\n",
              "0      1   0   0  619   0  42   2       0   1   1   1  101348\n",
              "1      0   0   1  608   0  41   1   83807   1   0   1  112542\n",
              "2      1   0   0  502   0  42   8  159660   3   1   0  113931\n",
              "3      1   0   0  699   0  39   1       0   2   0   0   93826\n",
              "4      0   0   1  850   0  43   2  125510   1   1   1   79084\n",
              "...   ..  ..  ..  ...  ..  ..  ..     ...  ..  ..  ..     ...\n",
              "9995   1   0   0  771   1  39   5       0   2   1   0   96270\n",
              "9996   1   0   0  516   1  35  10   57369   1   1   1  101699\n",
              "9997   1   0   0  709   0  36   7       0   1   0   1   42085\n",
              "9998   0   1   0  772   1  42   3   75075   2   1   0   92888\n",
              "9999   1   0   0  792   0  28   4  130142   1   1   0   38190\n",
              "\n",
              "[10000 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We remove the first column to avoid the dummy data trap\n",
        "'''Dummy data trap : A scenario where independent variables are highly correlated (one variable predicts the value of others).\n",
        "In one-hot encoding, one dummy variable can be predicted through other dummy variables, thus causing redundancy\n",
        "==> Using all dummy variables for regression models leads to dummy variable trap\n",
        "==> We exclude one of those dummy variables.'''\n",
        "\n",
        "X = X[:, 1:]\n",
        "df = pd.DataFrame(X)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VyiuOTxPTXMr",
        "outputId": "a8e6cd94-6e30-4d5a-9673-f9fcd149972a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-da5ef550-82fa-44bc-ae94-d57fc372dd49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>619</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>502</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>850</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>771</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>516</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>709</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>772</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>792</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da5ef550-82fa-44bc-ae94-d57fc372dd49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da5ef550-82fa-44bc-ae94-d57fc372dd49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da5ef550-82fa-44bc-ae94-d57fc372dd49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      0   1    2   3   4   5       6   7   8   9       10\n",
              "0      0   0  619   0  42   2       0   1   1   1  101348\n",
              "1      0   1  608   0  41   1   83807   1   0   1  112542\n",
              "2      0   0  502   0  42   8  159660   3   1   0  113931\n",
              "3      0   0  699   0  39   1       0   2   0   0   93826\n",
              "4      0   1  850   0  43   2  125510   1   1   1   79084\n",
              "...   ..  ..  ...  ..  ..  ..     ...  ..  ..  ..     ...\n",
              "9995   0   0  771   1  39   5       0   2   1   0   96270\n",
              "9996   0   0  516   1  35  10   57369   1   1   1  101699\n",
              "9997   0   0  709   0  36   7       0   1   0   1   42085\n",
              "9998   1   0  772   1  42   3   75075   2   1   0   92888\n",
              "9999   0   0  792   0  28   4  130142   1   1   0   38190\n",
              "\n",
              "[10000 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "nRgIICdtr_8w",
        "outputId": "25c563cc-75cc-4917-84ac-e3ed28a4e56b"
      },
      "source": [
        "#ONE-HOT ENCODING : Way 2 : using data frame :\n",
        "X_df = dataset.iloc[:, 3: 13]\n",
        "X_df = pd.concat([X_df, pd.get_dummies(X_df['Geography'], prefix='country', drop_first=True)], axis=1)  #drops the first column\n",
        "#axis = 1 means to concatenate along the columns (put one column beside another)\n",
        "X_df.drop(['Geography'], axis=1, inplace=True)  #get rid of the original Geography column\n",
        "X_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>country_Germany</th>\n",
              "      <th>country_Spain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>771</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>516</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>709</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>772</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>792</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      CreditScore  Gender  Age  ...  EstimatedSalary  country_Germany  country_Spain\n",
              "0             619  Female   42  ...        101348.88                0              0\n",
              "1             608  Female   41  ...        112542.58                0              1\n",
              "2             502  Female   42  ...        113931.57                0              0\n",
              "3             699  Female   39  ...         93826.63                0              0\n",
              "4             850  Female   43  ...         79084.10                0              1\n",
              "...           ...     ...  ...  ...              ...              ...            ...\n",
              "9995          771    Male   39  ...         96270.64                0              0\n",
              "9996          516    Male   35  ...        101699.77                0              0\n",
              "9997          709  Female   36  ...         42085.58                0              0\n",
              "9998          772    Male   42  ...         92888.52                1              0\n",
              "9999          792  Female   28  ...         38190.78                0              0\n",
              "\n",
              "[10000 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzmwnp05kucs"
      },
      "source": [
        "# Split the data into training and test set (20% for the test set)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state = 1) # We use random_state to make sure splitting contains the same data each time."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3nzIzK1woFBV",
        "outputId": "4158b78d-8c47-4f5c-b1c3-b0d64ae4cee1"
      },
      "source": [
        "#Standardise the data (x_standardised = (x - x_mean)/std_dev)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test) #note that we use the scale set from the training set to transform the test set\n",
        "df = pd.DataFrame(X_train)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4892c090-b81b-4e4c-ae20-52853c355bd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.230820</td>\n",
              "      <td>0.915091</td>\n",
              "      <td>-0.944500</td>\n",
              "      <td>-0.701742</td>\n",
              "      <td>0.588164</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>0.427402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.583124</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.251509</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>-0.944500</td>\n",
              "      <td>-0.355203</td>\n",
              "      <td>0.469851</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>-1.023271</td>\n",
              "      <td>-1.025493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.396330</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>0.774987</td>\n",
              "      <td>0.337876</td>\n",
              "      <td>0.858782</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>-0.944793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.044622</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>1.252622</td>\n",
              "      <td>0.337876</td>\n",
              "      <td>0.565605</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>-0.551941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.583124</td>\n",
              "      <td>1.746019</td>\n",
              "      <td>0.658795</td>\n",
              "      <td>0.915091</td>\n",
              "      <td>-0.562392</td>\n",
              "      <td>1.030954</td>\n",
              "      <td>0.730400</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>-1.553374</td>\n",
              "      <td>-1.023271</td>\n",
              "      <td>1.083388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>-0.303231</td>\n",
              "      <td>0.915091</td>\n",
              "      <td>0.774987</td>\n",
              "      <td>0.684415</td>\n",
              "      <td>0.495441</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>-0.579177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>0.348464</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>2.303420</td>\n",
              "      <td>-0.701742</td>\n",
              "      <td>0.076671</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>-1.023271</td>\n",
              "      <td>-0.529777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>-0.583124</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>0.224332</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>0.583933</td>\n",
              "      <td>1.377494</td>\n",
              "      <td>-1.225991</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>-0.140972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>-0.583124</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>0.131233</td>\n",
              "      <td>-1.092788</td>\n",
              "      <td>0.010771</td>\n",
              "      <td>1.030954</td>\n",
              "      <td>-1.225991</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>0.977259</td>\n",
              "      <td>0.017805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>1.714901</td>\n",
              "      <td>-0.572731</td>\n",
              "      <td>1.165670</td>\n",
              "      <td>0.915091</td>\n",
              "      <td>0.297352</td>\n",
              "      <td>0.337876</td>\n",
              "      <td>0.379950</td>\n",
              "      <td>-0.911510</td>\n",
              "      <td>0.643760</td>\n",
              "      <td>-1.023271</td>\n",
              "      <td>-1.158233</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4892c090-b81b-4e4c-ae20-52853c355bd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4892c090-b81b-4e4c-ae20-52853c355bd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4892c090-b81b-4e4c-ae20-52853c355bd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2         3         4         5         6   \\\n",
              "0     1.714901 -0.572731 -0.230820  0.915091 -0.944500 -0.701742  0.588164   \n",
              "1    -0.583124 -0.572731 -0.251509 -1.092788 -0.944500 -0.355203  0.469851   \n",
              "2     1.714901 -0.572731 -0.396330 -1.092788  0.774987  0.337876  0.858782   \n",
              "3     1.714901 -0.572731 -0.044622 -1.092788  1.252622  0.337876  0.565605   \n",
              "4    -0.583124  1.746019  0.658795  0.915091 -0.562392  1.030954  0.730400   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7995  1.714901 -0.572731 -0.303231  0.915091  0.774987  0.684415  0.495441   \n",
              "7996  1.714901 -0.572731  0.348464 -1.092788  2.303420 -0.701742  0.076671   \n",
              "7997 -0.583124 -0.572731  0.224332 -1.092788  0.583933  1.377494 -1.225991   \n",
              "7998 -0.583124 -0.572731  0.131233 -1.092788  0.010771  1.030954 -1.225991   \n",
              "7999  1.714901 -0.572731  1.165670  0.915091  0.297352  0.337876  0.379950   \n",
              "\n",
              "            7         8         9         10  \n",
              "0     0.802257 -1.553374  0.977259  0.427402  \n",
              "1     0.802257 -1.553374 -1.023271 -1.025493  \n",
              "2    -0.911510  0.643760  0.977259 -0.944793  \n",
              "3     0.802257 -1.553374  0.977259 -0.551941  \n",
              "4    -0.911510 -1.553374 -1.023271  1.083388  \n",
              "...        ...       ...       ...       ...  \n",
              "7995 -0.911510  0.643760  0.977259 -0.579177  \n",
              "7996 -0.911510  0.643760 -1.023271 -0.529777  \n",
              "7997 -0.911510  0.643760  0.977259 -0.140972  \n",
              "7998  0.802257  0.643760  0.977259  0.017805  \n",
              "7999 -0.911510  0.643760 -1.023271 -1.158233  \n",
              "\n",
              "[8000 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSnl4gWQpWkH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ea6c1035-459a-4d45-ce3a-adb9d514f7cd"
      },
      "source": [
        "#Building the model :\n",
        "#We use 2 dense layers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "#add first hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "#add 2nd hidden layer\n",
        "model.add(tf.keras.layers.Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "'''The number of units is mainly chosen by experience. In general, based on experimentation,\n",
        "setting it to the average between the number of the input nodes (11) and the number of the\n",
        "ouput nodes (1). Cross-validation can also be used to choose to choose the best parameters (parameter tuning).'''\n",
        "\n",
        "'''random_uniform: Weights are initialized to uniformly random small values between -0.05 to 0.05.\n",
        "random_normal: Weights are initialized according to a Gaussian distribution, with zero mean and a small standard deviation of 0.05.\n",
        "zero: All weights are initialized to zero.'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'random_uniform: Weights are initialized to uniformly random small values between -0.05 to 0.05.\\nrandom_normal: Weights are initialized according to a Gaussian distribution, with zero mean and a small standard deviation of 0.05.\\nzero: All weights are initialized to zero.'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T6K4Bpw7YFy"
      },
      "source": [
        "#Add the output layer\n",
        "model.add(keras.layers.Dense(units=1, kernel_initializer='uniform', activation='sigmoid')) #Sigmoid for binary, Softmax for multiclass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT7VQXeD8S31"
      },
      "source": [
        "#Compilation\n",
        "model.compile(optimizer = 'adam', loss ='binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Note: If you want to personalize an optimizer, do the following:\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "'''\n",
        "\n",
        "'''\n",
        "Here are the parameters of the Adam optimizer:\n",
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\",\n",
        "    **kwargs\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "id": "LfNziZ45f36O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Note: You can use a learning rate schedule to modulate how the learning rate of your optimizer changes over time\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-2,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "'''"
      ],
      "metadata": {
        "id": "ad20QEFWgWZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osRfJnL69ReK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc62ab7-82e1-4877-8998-5d50662229e5"
      },
      "source": [
        "#Training\n",
        "history = model.fit(X_train, y_train, batch_size = 10, epochs = 200, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "800/800 - 1s - loss: 0.4004 - accuracy: 0.8355 - 906ms/epoch - 1ms/step\n",
            "Epoch 2/200\n",
            "800/800 - 1s - loss: 0.3999 - accuracy: 0.8380 - 892ms/epoch - 1ms/step\n",
            "Epoch 3/200\n",
            "800/800 - 1s - loss: 0.4003 - accuracy: 0.8391 - 875ms/epoch - 1ms/step\n",
            "Epoch 4/200\n",
            "800/800 - 1s - loss: 0.4002 - accuracy: 0.8360 - 875ms/epoch - 1ms/step\n",
            "Epoch 5/200\n",
            "800/800 - 1s - loss: 0.4000 - accuracy: 0.8374 - 850ms/epoch - 1ms/step\n",
            "Epoch 6/200\n",
            "800/800 - 1s - loss: 0.4003 - accuracy: 0.8361 - 846ms/epoch - 1ms/step\n",
            "Epoch 7/200\n",
            "800/800 - 1s - loss: 0.4003 - accuracy: 0.8374 - 847ms/epoch - 1ms/step\n",
            "Epoch 8/200\n",
            "800/800 - 1s - loss: 0.3999 - accuracy: 0.8369 - 866ms/epoch - 1ms/step\n",
            "Epoch 9/200\n",
            "800/800 - 1s - loss: 0.3996 - accuracy: 0.8378 - 862ms/epoch - 1ms/step\n",
            "Epoch 10/200\n",
            "800/800 - 1s - loss: 0.4000 - accuracy: 0.8370 - 867ms/epoch - 1ms/step\n",
            "Epoch 11/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8365 - 855ms/epoch - 1ms/step\n",
            "Epoch 12/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8365 - 862ms/epoch - 1ms/step\n",
            "Epoch 13/200\n",
            "800/800 - 1s - loss: 0.3994 - accuracy: 0.8365 - 853ms/epoch - 1ms/step\n",
            "Epoch 14/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8375 - 873ms/epoch - 1ms/step\n",
            "Epoch 15/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8380 - 876ms/epoch - 1ms/step\n",
            "Epoch 16/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8365 - 865ms/epoch - 1ms/step\n",
            "Epoch 17/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8361 - 859ms/epoch - 1ms/step\n",
            "Epoch 18/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8366 - 868ms/epoch - 1ms/step\n",
            "Epoch 19/200\n",
            "800/800 - 1s - loss: 0.3995 - accuracy: 0.8357 - 865ms/epoch - 1ms/step\n",
            "Epoch 20/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8374 - 880ms/epoch - 1ms/step\n",
            "Epoch 21/200\n",
            "800/800 - 1s - loss: 0.3986 - accuracy: 0.8375 - 901ms/epoch - 1ms/step\n",
            "Epoch 22/200\n",
            "800/800 - 1s - loss: 0.3993 - accuracy: 0.8367 - 877ms/epoch - 1ms/step\n",
            "Epoch 23/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8378 - 858ms/epoch - 1ms/step\n",
            "Epoch 24/200\n",
            "800/800 - 1s - loss: 0.3982 - accuracy: 0.8367 - 895ms/epoch - 1ms/step\n",
            "Epoch 25/200\n",
            "800/800 - 1s - loss: 0.3991 - accuracy: 0.8367 - 872ms/epoch - 1ms/step\n",
            "Epoch 26/200\n",
            "800/800 - 1s - loss: 0.3988 - accuracy: 0.8370 - 936ms/epoch - 1ms/step\n",
            "Epoch 27/200\n",
            "800/800 - 1s - loss: 0.3982 - accuracy: 0.8379 - 906ms/epoch - 1ms/step\n",
            "Epoch 28/200\n",
            "800/800 - 1s - loss: 0.3983 - accuracy: 0.8350 - 878ms/epoch - 1ms/step\n",
            "Epoch 29/200\n",
            "800/800 - 1s - loss: 0.3985 - accuracy: 0.8364 - 878ms/epoch - 1ms/step\n",
            "Epoch 30/200\n",
            "800/800 - 1s - loss: 0.3989 - accuracy: 0.8370 - 887ms/epoch - 1ms/step\n",
            "Epoch 31/200\n",
            "800/800 - 1s - loss: 0.3979 - accuracy: 0.8355 - 880ms/epoch - 1ms/step\n",
            "Epoch 32/200\n",
            "800/800 - 1s - loss: 0.3986 - accuracy: 0.8365 - 914ms/epoch - 1ms/step\n",
            "Epoch 33/200\n",
            "800/800 - 1s - loss: 0.3985 - accuracy: 0.8360 - 902ms/epoch - 1ms/step\n",
            "Epoch 34/200\n",
            "800/800 - 1s - loss: 0.3984 - accuracy: 0.8370 - 911ms/epoch - 1ms/step\n",
            "Epoch 35/200\n",
            "800/800 - 1s - loss: 0.3983 - accuracy: 0.8376 - 901ms/epoch - 1ms/step\n",
            "Epoch 36/200\n",
            "800/800 - 1s - loss: 0.3984 - accuracy: 0.8378 - 879ms/epoch - 1ms/step\n",
            "Epoch 37/200\n",
            "800/800 - 1s - loss: 0.3985 - accuracy: 0.8390 - 846ms/epoch - 1ms/step\n",
            "Epoch 38/200\n",
            "800/800 - 1s - loss: 0.3983 - accuracy: 0.8375 - 896ms/epoch - 1ms/step\n",
            "Epoch 39/200\n",
            "800/800 - 1s - loss: 0.3981 - accuracy: 0.8384 - 869ms/epoch - 1ms/step\n",
            "Epoch 40/200\n",
            "800/800 - 1s - loss: 0.3985 - accuracy: 0.8378 - 868ms/epoch - 1ms/step\n",
            "Epoch 41/200\n",
            "800/800 - 1s - loss: 0.3981 - accuracy: 0.8388 - 853ms/epoch - 1ms/step\n",
            "Epoch 42/200\n",
            "800/800 - 1s - loss: 0.3982 - accuracy: 0.8380 - 886ms/epoch - 1ms/step\n",
            "Epoch 43/200\n",
            "800/800 - 1s - loss: 0.3981 - accuracy: 0.8384 - 890ms/epoch - 1ms/step\n",
            "Epoch 44/200\n",
            "800/800 - 1s - loss: 0.3982 - accuracy: 0.8374 - 872ms/epoch - 1ms/step\n",
            "Epoch 45/200\n",
            "800/800 - 1s - loss: 0.3982 - accuracy: 0.8384 - 852ms/epoch - 1ms/step\n",
            "Epoch 46/200\n",
            "800/800 - 1s - loss: 0.3982 - accuracy: 0.8376 - 863ms/epoch - 1ms/step\n",
            "Epoch 47/200\n",
            "800/800 - 1s - loss: 0.3981 - accuracy: 0.8375 - 879ms/epoch - 1ms/step\n",
            "Epoch 48/200\n",
            "800/800 - 1s - loss: 0.3982 - accuracy: 0.8375 - 851ms/epoch - 1ms/step\n",
            "Epoch 49/200\n",
            "800/800 - 1s - loss: 0.3977 - accuracy: 0.8391 - 911ms/epoch - 1ms/step\n",
            "Epoch 50/200\n",
            "800/800 - 1s - loss: 0.3981 - accuracy: 0.8393 - 870ms/epoch - 1ms/step\n",
            "Epoch 51/200\n",
            "800/800 - 1s - loss: 0.3983 - accuracy: 0.8389 - 870ms/epoch - 1ms/step\n",
            "Epoch 52/200\n",
            "800/800 - 1s - loss: 0.3979 - accuracy: 0.8390 - 896ms/epoch - 1ms/step\n",
            "Epoch 53/200\n",
            "800/800 - 1s - loss: 0.3978 - accuracy: 0.8371 - 879ms/epoch - 1ms/step\n",
            "Epoch 54/200\n",
            "800/800 - 1s - loss: 0.3979 - accuracy: 0.8370 - 870ms/epoch - 1ms/step\n",
            "Epoch 55/200\n",
            "800/800 - 1s - loss: 0.3980 - accuracy: 0.8381 - 850ms/epoch - 1ms/step\n",
            "Epoch 56/200\n",
            "800/800 - 1s - loss: 0.3976 - accuracy: 0.8381 - 863ms/epoch - 1ms/step\n",
            "Epoch 57/200\n",
            "800/800 - 1s - loss: 0.3971 - accuracy: 0.8386 - 875ms/epoch - 1ms/step\n",
            "Epoch 58/200\n",
            "800/800 - 1s - loss: 0.3973 - accuracy: 0.8379 - 901ms/epoch - 1ms/step\n",
            "Epoch 59/200\n",
            "800/800 - 1s - loss: 0.3970 - accuracy: 0.8400 - 912ms/epoch - 1ms/step\n",
            "Epoch 60/200\n",
            "800/800 - 1s - loss: 0.3972 - accuracy: 0.8365 - 918ms/epoch - 1ms/step\n",
            "Epoch 61/200\n",
            "800/800 - 1s - loss: 0.3971 - accuracy: 0.8389 - 887ms/epoch - 1ms/step\n",
            "Epoch 62/200\n",
            "800/800 - 1s - loss: 0.3970 - accuracy: 0.8379 - 890ms/epoch - 1ms/step\n",
            "Epoch 63/200\n",
            "800/800 - 1s - loss: 0.3973 - accuracy: 0.8384 - 848ms/epoch - 1ms/step\n",
            "Epoch 64/200\n",
            "800/800 - 1s - loss: 0.3972 - accuracy: 0.8378 - 863ms/epoch - 1ms/step\n",
            "Epoch 65/200\n",
            "800/800 - 1s - loss: 0.3966 - accuracy: 0.8380 - 936ms/epoch - 1ms/step\n",
            "Epoch 66/200\n",
            "800/800 - 1s - loss: 0.3972 - accuracy: 0.8396 - 868ms/epoch - 1ms/step\n",
            "Epoch 67/200\n",
            "800/800 - 1s - loss: 0.3969 - accuracy: 0.8366 - 860ms/epoch - 1ms/step\n",
            "Epoch 68/200\n",
            "800/800 - 1s - loss: 0.3972 - accuracy: 0.8367 - 869ms/epoch - 1ms/step\n",
            "Epoch 69/200\n",
            "800/800 - 1s - loss: 0.3971 - accuracy: 0.8379 - 896ms/epoch - 1ms/step\n",
            "Epoch 70/200\n",
            "800/800 - 1s - loss: 0.3966 - accuracy: 0.8374 - 856ms/epoch - 1ms/step\n",
            "Epoch 71/200\n",
            "800/800 - 1s - loss: 0.3968 - accuracy: 0.8376 - 879ms/epoch - 1ms/step\n",
            "Epoch 72/200\n",
            "800/800 - 1s - loss: 0.3969 - accuracy: 0.8378 - 886ms/epoch - 1ms/step\n",
            "Epoch 73/200\n",
            "800/800 - 1s - loss: 0.3964 - accuracy: 0.8395 - 873ms/epoch - 1ms/step\n",
            "Epoch 74/200\n",
            "800/800 - 1s - loss: 0.3964 - accuracy: 0.8372 - 864ms/epoch - 1ms/step\n",
            "Epoch 75/200\n",
            "800/800 - 1s - loss: 0.3966 - accuracy: 0.8372 - 885ms/epoch - 1ms/step\n",
            "Epoch 76/200\n",
            "800/800 - 1s - loss: 0.3963 - accuracy: 0.8397 - 874ms/epoch - 1ms/step\n",
            "Epoch 77/200\n",
            "800/800 - 1s - loss: 0.3966 - accuracy: 0.8388 - 873ms/epoch - 1ms/step\n",
            "Epoch 78/200\n",
            "800/800 - 1s - loss: 0.3961 - accuracy: 0.8388 - 851ms/epoch - 1ms/step\n",
            "Epoch 79/200\n",
            "800/800 - 1s - loss: 0.3967 - accuracy: 0.8384 - 874ms/epoch - 1ms/step\n",
            "Epoch 80/200\n",
            "800/800 - 1s - loss: 0.3964 - accuracy: 0.8378 - 877ms/epoch - 1ms/step\n",
            "Epoch 81/200\n",
            "800/800 - 1s - loss: 0.3966 - accuracy: 0.8374 - 852ms/epoch - 1ms/step\n",
            "Epoch 82/200\n",
            "800/800 - 1s - loss: 0.3959 - accuracy: 0.8384 - 866ms/epoch - 1ms/step\n",
            "Epoch 83/200\n",
            "800/800 - 1s - loss: 0.3965 - accuracy: 0.8363 - 891ms/epoch - 1ms/step\n",
            "Epoch 84/200\n",
            "800/800 - 1s - loss: 0.3962 - accuracy: 0.8390 - 891ms/epoch - 1ms/step\n",
            "Epoch 85/200\n",
            "800/800 - 1s - loss: 0.3955 - accuracy: 0.8381 - 873ms/epoch - 1ms/step\n",
            "Epoch 86/200\n",
            "800/800 - 1s - loss: 0.3963 - accuracy: 0.8374 - 911ms/epoch - 1ms/step\n",
            "Epoch 87/200\n",
            "800/800 - 1s - loss: 0.3963 - accuracy: 0.8374 - 885ms/epoch - 1ms/step\n",
            "Epoch 88/200\n",
            "800/800 - 1s - loss: 0.3961 - accuracy: 0.8379 - 907ms/epoch - 1ms/step\n",
            "Epoch 89/200\n",
            "800/800 - 1s - loss: 0.3961 - accuracy: 0.8371 - 857ms/epoch - 1ms/step\n",
            "Epoch 90/200\n",
            "800/800 - 1s - loss: 0.3958 - accuracy: 0.8375 - 861ms/epoch - 1ms/step\n",
            "Epoch 91/200\n",
            "800/800 - 1s - loss: 0.3964 - accuracy: 0.8384 - 899ms/epoch - 1ms/step\n",
            "Epoch 92/200\n",
            "800/800 - 1s - loss: 0.3961 - accuracy: 0.8395 - 881ms/epoch - 1ms/step\n",
            "Epoch 93/200\n",
            "800/800 - 1s - loss: 0.3959 - accuracy: 0.8372 - 869ms/epoch - 1ms/step\n",
            "Epoch 94/200\n",
            "800/800 - 1s - loss: 0.3962 - accuracy: 0.8376 - 884ms/epoch - 1ms/step\n",
            "Epoch 95/200\n",
            "800/800 - 1s - loss: 0.3963 - accuracy: 0.8378 - 882ms/epoch - 1ms/step\n",
            "Epoch 96/200\n",
            "800/800 - 1s - loss: 0.3963 - accuracy: 0.8384 - 883ms/epoch - 1ms/step\n",
            "Epoch 97/200\n",
            "800/800 - 1s - loss: 0.3965 - accuracy: 0.8380 - 857ms/epoch - 1ms/step\n",
            "Epoch 98/200\n",
            "800/800 - 1s - loss: 0.3960 - accuracy: 0.8381 - 865ms/epoch - 1ms/step\n",
            "Epoch 99/200\n",
            "800/800 - 1s - loss: 0.3961 - accuracy: 0.8359 - 864ms/epoch - 1ms/step\n",
            "Epoch 100/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8399 - 849ms/epoch - 1ms/step\n",
            "Epoch 101/200\n",
            "800/800 - 1s - loss: 0.3956 - accuracy: 0.8378 - 875ms/epoch - 1ms/step\n",
            "Epoch 102/200\n",
            "800/800 - 1s - loss: 0.3961 - accuracy: 0.8382 - 873ms/epoch - 1ms/step\n",
            "Epoch 103/200\n",
            "800/800 - 1s - loss: 0.3961 - accuracy: 0.8382 - 887ms/epoch - 1ms/step\n",
            "Epoch 104/200\n",
            "800/800 - 1s - loss: 0.3962 - accuracy: 0.8388 - 883ms/epoch - 1ms/step\n",
            "Epoch 105/200\n",
            "800/800 - 1s - loss: 0.3961 - accuracy: 0.8380 - 844ms/epoch - 1ms/step\n",
            "Epoch 106/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8390 - 855ms/epoch - 1ms/step\n",
            "Epoch 107/200\n",
            "800/800 - 1s - loss: 0.3964 - accuracy: 0.8389 - 846ms/epoch - 1ms/step\n",
            "Epoch 108/200\n",
            "800/800 - 1s - loss: 0.3964 - accuracy: 0.8393 - 896ms/epoch - 1ms/step\n",
            "Epoch 109/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8376 - 907ms/epoch - 1ms/step\n",
            "Epoch 110/200\n",
            "800/800 - 1s - loss: 0.3958 - accuracy: 0.8386 - 868ms/epoch - 1ms/step\n",
            "Epoch 111/200\n",
            "800/800 - 1s - loss: 0.3955 - accuracy: 0.8388 - 866ms/epoch - 1ms/step\n",
            "Epoch 112/200\n",
            "800/800 - 1s - loss: 0.3959 - accuracy: 0.8399 - 872ms/epoch - 1ms/step\n",
            "Epoch 113/200\n",
            "800/800 - 1s - loss: 0.3957 - accuracy: 0.8369 - 867ms/epoch - 1ms/step\n",
            "Epoch 114/200\n",
            "800/800 - 1s - loss: 0.3957 - accuracy: 0.8379 - 865ms/epoch - 1ms/step\n",
            "Epoch 115/200\n",
            "800/800 - 1s - loss: 0.3959 - accuracy: 0.8396 - 871ms/epoch - 1ms/step\n",
            "Epoch 116/200\n",
            "800/800 - 2s - loss: 0.3959 - accuracy: 0.8401 - 2s/epoch - 2ms/step\n",
            "Epoch 117/200\n",
            "800/800 - 2s - loss: 0.3958 - accuracy: 0.8389 - 2s/epoch - 2ms/step\n",
            "Epoch 118/200\n",
            "800/800 - 2s - loss: 0.3959 - accuracy: 0.8391 - 2s/epoch - 2ms/step\n",
            "Epoch 119/200\n",
            "800/800 - 2s - loss: 0.3960 - accuracy: 0.8385 - 2s/epoch - 3ms/step\n",
            "Epoch 120/200\n",
            "800/800 - 1s - loss: 0.3956 - accuracy: 0.8369 - 864ms/epoch - 1ms/step\n",
            "Epoch 121/200\n",
            "800/800 - 1s - loss: 0.3957 - accuracy: 0.8388 - 848ms/epoch - 1ms/step\n",
            "Epoch 122/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8369 - 854ms/epoch - 1ms/step\n",
            "Epoch 123/200\n",
            "800/800 - 1s - loss: 0.3957 - accuracy: 0.8397 - 849ms/epoch - 1ms/step\n",
            "Epoch 124/200\n",
            "800/800 - 1s - loss: 0.3956 - accuracy: 0.8397 - 860ms/epoch - 1ms/step\n",
            "Epoch 125/200\n",
            "800/800 - 1s - loss: 0.3958 - accuracy: 0.8393 - 869ms/epoch - 1ms/step\n",
            "Epoch 126/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8374 - 892ms/epoch - 1ms/step\n",
            "Epoch 127/200\n",
            "800/800 - 1s - loss: 0.3953 - accuracy: 0.8386 - 907ms/epoch - 1ms/step\n",
            "Epoch 128/200\n",
            "800/800 - 1s - loss: 0.3955 - accuracy: 0.8390 - 838ms/epoch - 1ms/step\n",
            "Epoch 129/200\n",
            "800/800 - 1s - loss: 0.3962 - accuracy: 0.8378 - 877ms/epoch - 1ms/step\n",
            "Epoch 130/200\n",
            "800/800 - 1s - loss: 0.3950 - accuracy: 0.8396 - 857ms/epoch - 1ms/step\n",
            "Epoch 131/200\n",
            "800/800 - 1s - loss: 0.3956 - accuracy: 0.8378 - 860ms/epoch - 1ms/step\n",
            "Epoch 132/200\n",
            "800/800 - 1s - loss: 0.3956 - accuracy: 0.8388 - 869ms/epoch - 1ms/step\n",
            "Epoch 133/200\n",
            "800/800 - 1s - loss: 0.3956 - accuracy: 0.8385 - 911ms/epoch - 1ms/step\n",
            "Epoch 134/200\n",
            "800/800 - 1s - loss: 0.3955 - accuracy: 0.8369 - 880ms/epoch - 1ms/step\n",
            "Epoch 135/200\n",
            "800/800 - 1s - loss: 0.3950 - accuracy: 0.8374 - 876ms/epoch - 1ms/step\n",
            "Epoch 136/200\n",
            "800/800 - 1s - loss: 0.3956 - accuracy: 0.8389 - 855ms/epoch - 1ms/step\n",
            "Epoch 137/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8379 - 923ms/epoch - 1ms/step\n",
            "Epoch 138/200\n",
            "800/800 - 1s - loss: 0.3957 - accuracy: 0.8385 - 891ms/epoch - 1ms/step\n",
            "Epoch 139/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8379 - 859ms/epoch - 1ms/step\n",
            "Epoch 140/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8379 - 862ms/epoch - 1ms/step\n",
            "Epoch 141/200\n",
            "800/800 - 1s - loss: 0.3957 - accuracy: 0.8359 - 860ms/epoch - 1ms/step\n",
            "Epoch 142/200\n",
            "800/800 - 1s - loss: 0.3957 - accuracy: 0.8375 - 845ms/epoch - 1ms/step\n",
            "Epoch 143/200\n",
            "800/800 - 1s - loss: 0.3955 - accuracy: 0.8389 - 882ms/epoch - 1ms/step\n",
            "Epoch 144/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8390 - 881ms/epoch - 1ms/step\n",
            "Epoch 145/200\n",
            "800/800 - 1s - loss: 0.3953 - accuracy: 0.8390 - 873ms/epoch - 1ms/step\n",
            "Epoch 146/200\n",
            "800/800 - 1s - loss: 0.3956 - accuracy: 0.8372 - 860ms/epoch - 1ms/step\n",
            "Epoch 147/200\n",
            "800/800 - 1s - loss: 0.3960 - accuracy: 0.8364 - 865ms/epoch - 1ms/step\n",
            "Epoch 148/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8401 - 892ms/epoch - 1ms/step\n",
            "Epoch 149/200\n",
            "800/800 - 1s - loss: 0.3949 - accuracy: 0.8380 - 850ms/epoch - 1ms/step\n",
            "Epoch 150/200\n",
            "800/800 - 1s - loss: 0.3952 - accuracy: 0.8393 - 907ms/epoch - 1ms/step\n",
            "Epoch 151/200\n",
            "800/800 - 1s - loss: 0.3952 - accuracy: 0.8381 - 873ms/epoch - 1ms/step\n",
            "Epoch 152/200\n",
            "800/800 - 1s - loss: 0.3955 - accuracy: 0.8369 - 873ms/epoch - 1ms/step\n",
            "Epoch 153/200\n",
            "800/800 - 1s - loss: 0.3953 - accuracy: 0.8389 - 857ms/epoch - 1ms/step\n",
            "Epoch 154/200\n",
            "800/800 - 1s - loss: 0.3950 - accuracy: 0.8367 - 850ms/epoch - 1ms/step\n",
            "Epoch 155/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8378 - 865ms/epoch - 1ms/step\n",
            "Epoch 156/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8384 - 875ms/epoch - 1ms/step\n",
            "Epoch 157/200\n",
            "800/800 - 1s - loss: 0.3950 - accuracy: 0.8386 - 881ms/epoch - 1ms/step\n",
            "Epoch 158/200\n",
            "800/800 - 1s - loss: 0.3955 - accuracy: 0.8382 - 892ms/epoch - 1ms/step\n",
            "Epoch 159/200\n",
            "800/800 - 1s - loss: 0.3953 - accuracy: 0.8381 - 861ms/epoch - 1ms/step\n",
            "Epoch 160/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8369 - 853ms/epoch - 1ms/step\n",
            "Epoch 161/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8386 - 881ms/epoch - 1ms/step\n",
            "Epoch 162/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8375 - 893ms/epoch - 1ms/step\n",
            "Epoch 163/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8380 - 855ms/epoch - 1ms/step\n",
            "Epoch 164/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8384 - 863ms/epoch - 1ms/step\n",
            "Epoch 165/200\n",
            "800/800 - 1s - loss: 0.3954 - accuracy: 0.8388 - 871ms/epoch - 1ms/step\n",
            "Epoch 166/200\n",
            "800/800 - 1s - loss: 0.3949 - accuracy: 0.8384 - 894ms/epoch - 1ms/step\n",
            "Epoch 167/200\n",
            "800/800 - 1s - loss: 0.3951 - accuracy: 0.8361 - 861ms/epoch - 1ms/step\n",
            "Epoch 168/200\n",
            "800/800 - 1s - loss: 0.3950 - accuracy: 0.8369 - 862ms/epoch - 1ms/step\n",
            "Epoch 169/200\n",
            "800/800 - 1s - loss: 0.3950 - accuracy: 0.8374 - 859ms/epoch - 1ms/step\n",
            "Epoch 170/200\n",
            "800/800 - 1s - loss: 0.3947 - accuracy: 0.8396 - 830ms/epoch - 1ms/step\n",
            "Epoch 171/200\n",
            "800/800 - 1s - loss: 0.3952 - accuracy: 0.8360 - 882ms/epoch - 1ms/step\n",
            "Epoch 172/200\n",
            "800/800 - 1s - loss: 0.3952 - accuracy: 0.8380 - 860ms/epoch - 1ms/step\n",
            "Epoch 173/200\n",
            "800/800 - 1s - loss: 0.3950 - accuracy: 0.8405 - 898ms/epoch - 1ms/step\n",
            "Epoch 174/200\n",
            "800/800 - 1s - loss: 0.3939 - accuracy: 0.8371 - 921ms/epoch - 1ms/step\n",
            "Epoch 175/200\n",
            "800/800 - 1s - loss: 0.3949 - accuracy: 0.8380 - 910ms/epoch - 1ms/step\n",
            "Epoch 176/200\n",
            "800/800 - 1s - loss: 0.3949 - accuracy: 0.8403 - 879ms/epoch - 1ms/step\n",
            "Epoch 177/200\n",
            "800/800 - 1s - loss: 0.3946 - accuracy: 0.8379 - 843ms/epoch - 1ms/step\n",
            "Epoch 178/200\n",
            "800/800 - 1s - loss: 0.3948 - accuracy: 0.8384 - 852ms/epoch - 1ms/step\n",
            "Epoch 179/200\n",
            "800/800 - 1s - loss: 0.3946 - accuracy: 0.8375 - 878ms/epoch - 1ms/step\n",
            "Epoch 180/200\n",
            "800/800 - 1s - loss: 0.3949 - accuracy: 0.8376 - 868ms/epoch - 1ms/step\n",
            "Epoch 181/200\n",
            "800/800 - 1s - loss: 0.3948 - accuracy: 0.8376 - 865ms/epoch - 1ms/step\n",
            "Epoch 182/200\n",
            "800/800 - 1s - loss: 0.3942 - accuracy: 0.8369 - 861ms/epoch - 1ms/step\n",
            "Epoch 183/200\n",
            "800/800 - 1s - loss: 0.3944 - accuracy: 0.8379 - 857ms/epoch - 1ms/step\n",
            "Epoch 184/200\n",
            "800/800 - 1s - loss: 0.3941 - accuracy: 0.8384 - 848ms/epoch - 1ms/step\n",
            "Epoch 185/200\n",
            "800/800 - 1s - loss: 0.3945 - accuracy: 0.8404 - 886ms/epoch - 1ms/step\n",
            "Epoch 186/200\n",
            "800/800 - 1s - loss: 0.3941 - accuracy: 0.8404 - 860ms/epoch - 1ms/step\n",
            "Epoch 187/200\n",
            "800/800 - 1s - loss: 0.3933 - accuracy: 0.8404 - 865ms/epoch - 1ms/step\n",
            "Epoch 188/200\n",
            "800/800 - 1s - loss: 0.3936 - accuracy: 0.8400 - 852ms/epoch - 1ms/step\n",
            "Epoch 189/200\n",
            "800/800 - 1s - loss: 0.3933 - accuracy: 0.8389 - 853ms/epoch - 1ms/step\n",
            "Epoch 190/200\n",
            "800/800 - 1s - loss: 0.3929 - accuracy: 0.8390 - 884ms/epoch - 1ms/step\n",
            "Epoch 191/200\n",
            "800/800 - 1s - loss: 0.3928 - accuracy: 0.8378 - 857ms/epoch - 1ms/step\n",
            "Epoch 192/200\n",
            "800/800 - 1s - loss: 0.3929 - accuracy: 0.8397 - 854ms/epoch - 1ms/step\n",
            "Epoch 193/200\n",
            "800/800 - 1s - loss: 0.3922 - accuracy: 0.8409 - 886ms/epoch - 1ms/step\n",
            "Epoch 194/200\n",
            "800/800 - 1s - loss: 0.3922 - accuracy: 0.8403 - 913ms/epoch - 1ms/step\n",
            "Epoch 195/200\n",
            "800/800 - 1s - loss: 0.3917 - accuracy: 0.8401 - 881ms/epoch - 1ms/step\n",
            "Epoch 196/200\n",
            "800/800 - 1s - loss: 0.3919 - accuracy: 0.8393 - 879ms/epoch - 1ms/step\n",
            "Epoch 197/200\n",
            "800/800 - 1s - loss: 0.3911 - accuracy: 0.8399 - 890ms/epoch - 1ms/step\n",
            "Epoch 198/200\n",
            "800/800 - 1s - loss: 0.3902 - accuracy: 0.8406 - 865ms/epoch - 1ms/step\n",
            "Epoch 199/200\n",
            "800/800 - 1s - loss: 0.3902 - accuracy: 0.8406 - 892ms/epoch - 1ms/step\n",
            "Epoch 200/200\n",
            "800/800 - 1s - loss: 0.3892 - accuracy: 0.8404 - 854ms/epoch - 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiTgXcTKdGKj",
        "outputId": "d1c620fb-14f4-4077-cc0c-5a3e18fb4a76"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4004 - accuracy: 0.8340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCtgI6CT-Hb3",
        "outputId": "219d85f5-d204-4ea4-9de9-04f0e443e716"
      },
      "source": [
        "#Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False]\n",
            " [False]\n",
            " [False]\n",
            " ...\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg48e7y1BNbP",
        "outputId": "2a992a23-f3fe-4b11-fff8-25e3910107db"
      },
      "source": [
        "#Predict using the info of a new customer\n",
        "new_customer = [[0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]\n",
        "new_customer = sc.transform(new_customer)\n",
        "new_prediction = model.predict(new_customer)\n",
        "new_prediction = (new_prediction > 0.5)\n",
        "print(new_prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zUq3xA1E_u9b",
        "outputId": "dfe87c6c-6349-4bfc-c6b2-d29bc0257dfc"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy','loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxcdZ3v/9enqnrf0+nsO4Q1ZIGwKoiDKMiuMuKCJgoM4+DoOOrF0VF+6r0643Wcn17uaGYGxQUBURzGHZRVtiQQICwhIWTpkKX39N5dVZ/7x/d0UwmdpBJS3Qnn/Xw8+tFVZ/2cU6e+77NUnTJ3R0RE4isx1gWIiMjYUhCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQgkVszsB2b21TyH3WBmbyt0TSJjTUEgIhJzCgKRw5CZpca6BnnjUBDIISc6JfMZM3vazLrN7D/NbKKZ/dbMOs3sHjOryxn+YjN71szazew+Mzs2p98iM3siGu82oHS3eV1oZquicR82s/l51niBmT1pZjvNbLOZ3bBb/zdH02uP+i+JupeZ2TfNbKOZdZjZQ1G3s82scYT18Lbo8Q1mdoeZ/djMdgJLzOwUM3skmsdWM/s/ZlacM/7xZna3mbWa2XYz+wczm2RmPWZWnzPciWbWZGZF+Sy7vPEoCORQ9W7gXOAo4CLgt8A/AA2E7fZvAczsKOCnwCejfr8B/tvMiqNG8ZfAj4BxwM+i6RKNuwi4CfgroB74HnCXmZXkUV838CGgFrgA+GszuzSa7syo3u9ENS0EVkXj/W/gJOCMqKbPAtk818klwB3RPH8CZIC/A8YDpwPnAB+LaqgC7gF+B0wBjgT+6O7bgPuAv8yZ7pXAre4+mGcd8gajIJBD1Xfcfbu7bwEeBB5z9yfdvQ+4E1gUDfde4NfufnfUkP1voIzQ0J4GFAH/6u6D7n4HsDxnHtcA33P3x9w94+43A/3ReHvl7ve5+zPunnX3pwlh9Jao9/uBe9z9p9F8W9x9lZklgI8An3D3LdE8H3b3/jzXySPu/stonr3uvtLdH3X3tLtvIATZUA0XAtvc/Zvu3ufune7+WNTvZuCDAGaWBN5HCEuJKQWBHKq25zzuHeF5ZfR4CrBxqIe7Z4HNwNSo3xbf9c6KG3MezwT+Pjq10m5m7cD0aLy9MrNTzeze6JRKB3AtYc+caBovjTDaeMKpqZH65WPzbjUcZWa/MrNt0emi/5VHDQD/BRxnZrMJR10d7v74AdYkbwAKAjncvUJo0AEwMyM0gluArcDUqNuQGTmPNwP/091rc/7K3f2necz3FuAuYLq71wDfBYbmsxk4YoRxmoG+PfTrBspzliNJOK2Ua/dbBf8b8AIw192rCafOcmuYM1Lh0VHV7YSjgivR0UDsKQjkcHc7cIGZnRNd7Px7wumdh4FHgDTwt2ZWZGbvAk7JGfffgWujvXszs4roInBVHvOtAlrdvc/MTiGcDhryE+BtZvaXZpYys3ozWxgdrdwE/IuZTTGzpJmdHl2TeBEojeZfBHwB2Ne1iipgJ9BlZscAf53T71fAZDP7pJmVmFmVmZ2a0/+HwBLgYhQEsacgkMOau68h7Nl+h7DHfRFwkbsPuPsA8C5Cg9dKuJ7wi5xxVwBXA/8HaAPWRcPm42PAl82sE/giIZCGprsJeCchlFoJF4oXRL0/DTxDuFbRCvwTkHD3jmia/0E4mukGdvkU0Qg+TQigTkKo3ZZTQyfhtM9FwDZgLfDWnP5/JlykfsLdc0+XSQyZfphGJJ7M7E/ALe7+H2Ndi4wtBYFIDJnZycDdhGscnWNdj4wtnRoSiRkzu5nwHYNPKgQEdEQgIhJ7OiIQEYm5w+7GVePHj/dZs2aNdRkiIoeVlStXNrv77t9NAQ7DIJg1axYrVqwY6zJERA4rZrbHjwnr1JCISMwpCEREYk5BICIScwoCEZGYUxCIiMScgkBEJOYUBCIiMXfYfY9ADl0D6SyOU5JKjnUpoy6dyZJKvv79Kndn19/RCd2ausKvWU6oKs1rGplsmE4yYfscfrT0pzP0DmSoLS8e61J20d2f5tlXdnLyrLrhdb+js4/iZGK/a326sZ2WroHh5zXlRcwcV0595Wt/WqKps58/Pr+d/nSWuRMqqSotYkptKfWVJfSnM7y4rYsXt4dbQZUWJSktSnDM5Gqm1pa9jqUdWeyCYN2OLu5atYVtO/v49NuPZkL1yG8sd2dHZz/1FcUjvsHdneauAV5p72XuxErKi/e8KtOZLMmEYWZ09adJmlFWvGtj2dLVT2lRkoqS/F6SbNZp6R6gqz/NfWt2sGZbJxfOn0JlaYq12zuZNb6CHTv7eWZLB0c0VFBTVkR77yALp9dSmkqyYmMr0+rKmdNQQVEyQVHSWLWpnR89upEdnaHRmVhdgplRVZLiqjNnc+SEKrJZ55ktHezo7Kc/nWFTaw8VxSlKixJ88w8vUl1WxC1Xncr9LzbxcnM3p86pp7NvkHTGOXJCJZms8+DaJn76+GbedeJU/u5tR5FIGH2DGRrbeplaW0ZR0ujuz9DaM8CtyzfxyEstfPTNs7l4wRReaurmM3c8xSvtvZxxxHiqSlNUlKSYXlfOjHHhr6GqhFWb2xnMZDlz7nj++PwO7n5uO8dPrWbxzHEcPamKhEFr9wDtvYPMHFdOKplgR2cf969p4r4Xm1i3vYulb5rF5Yun09o9wPadfWzr6KO5q5+asiKqSovIuHPKrHGsb+7i/f/+GAum1/Kxs4+grXuAvnSGnoGwfuoriplYXcqj61vp6B0gYUZTZz+z6it4z+JprNnWyabWHpq7+rl/TRPjKor53pUnUV9Rwo8f28j3//wyzVHjcvKsOmrKinF35k6s4vx5k5jTUMEdKxuZUlvGEQ0VXPvjJ1i3o4uEwZTaMs46qoGlZ8ziiU1trN6yk47eQc44op6W7gFuX7GZtxzVwFuOamD5hjaSCZg9vpIL50+mtCjJuh2d3LFyC+Mqijh2cjUbmrupKEkxe3zYbuY0VFBenCKbdR5Y28Rvn9lG90CaTNZJJIx3nziVtx49ge6BDB/490dZs72Ta846gqbOfnbs7ONtx03kvOMnkXXnJ49t4uhJVbz9uIm09QyyeksHLzd309YzQCph1JQXU1tWxHFTqplVX8FvV2+lqy/NWUc10DuY4ZX2Xra09fJKey/96SyTa0q5cMEUxuc0wveu2cFXf/Uc7zxhMp869yieauzgk7c+yYaWHv7qrDn8zV8cyW2Pb+abd6+htCjJ584/JmqEk5w0s47SoiTpTBZ3qC0vGm5T1u3o4vYVm7l3TdOI79eF02uZWldGcTLBW4+ZwMPrmrl9xWayI9zqbWptGTs6+xjMvLbnVy+dxwdPm/nakV6nw+6mc4sXL/YD+WZxJuv8233r+NY9a3F3UskEDZUlnDC1hhUb2zhz7nh6BzI8/FIzDVUldPSmae7qpziV4KiJlRw1oWq48e5PZ3ns5RY2t/YCUF2a4oL5U5hWV0Z7zwBd/RnmT6vhz+ua+cOz2xnIZKmvKGZKbRnPbd1JMmEsnF5L0oy+dIaOnkHWN3dTV17Ev16xiPaeAR5c28yG5m5OP6KehdNreXxDKxVR2Dy0tpnVr3TQM5AZXr6yoiS9g5nXLHfCGHFj25PxlcUcM6maTNbZ0dmHA9s7+ugdzDCrvoKdfWG9jOTYydVsbOnGHXoHM5jBnjavuRMqWbuji8Uz66goSbFiQyvdAyPXP62unE2tPVSXpugZyFBVmuK0OfWs3NjGYCZLV396xDcNwNETq1izvXOX9ZNMGAakoxVTVpQklTA6+9MANFSV0FBZMvxaZfayAmeMK6c/nSGThb7BDF3RNIYUJW24tqrSFBOrS8lknfqKYla/0kHfYBaAklRieLkeeamFnoEMA5ksmazz1qNDQ93Zl+Z3z24j62FHYH1zF4MZp7w4ObwtJAzGVRTzwdNmks6EYe5+bvtwDdWlKcqKk2zfGV7DhdNreWZLB5msU5Q03MN6qa8oprQoyZb2XlIJG15XuxtfWcJ7TprGH57dxvrmbmrKihhXUUwqYbT3DtLU2c+c8RUUpxKs3dHFaXPG8ed1LZQXJ6mvLGZza5h+SSox/PrPGFfO5raePW47EBrh9p7BEfslDFKJBAOZLLXlRVx+0jQ2tfawZlsnG1p6hsc9ZfY4lm9oZXJ1KSfOrONXT28dnsZfHDOBlu4BntrcvscaxlcWk0zY8LqsKknx8XOO5JTZ9UDYWWzrGeC5V3Zy9/M76OwbpKNnkJbuEGwfPG0mV5wyndqyYtY3ddHVn2ZdUxfPbtnJ9HHlnDC1hmMmV5FKGH2DWfoGM0ypLaOhal8/XDcyM1vp7otH7BeXIPjmH9bwnT+t48L5k/nSRcezraOPpT94nKzDqbPH8ed1zRSnkvzFMQ109A5SVpTkhGm1bOvo5YVtnazb0cVgJrxpzYwF02o4bU49k2pK+e3qbTzwYhOdfWmKUwlKUgk6+9JUlaS4dNFUGqpK2NTaQ2NbDyfNrKN/MMsTm9pIJiwcBRSnmDe1ml+ueoV1O7oAqK8oZlpdGU9v6cB91wblhKk1nDSzjtnjK6goSTF/Wg0zxpXzh+e2Y8Cxk6vY3NpLVWmKBdNr2djSTe9AlvKSJI+/3MpAOssps8expa2XLe29pLNOOpNlfGUJF0R7grlauvq56c8vs7Glh1TCOPvoCRw5oZJkwpg+rpydvYM0tvVy0sw6Vm5s44v/tZorT5/JxQum8HRjB3Xl4Q3zUlMXxckEs8ZXcERDBf/50MvctnwzxakE86fVcuKMWrZ1hPCpLElRWZJi8aw6ZtZXcNvyzbywbSdlxUk+8qbZTMw5kstknW07+9jc2sOm1h62tvdxzOQqduzs41v3rOX8eZP44kXHsWNnPys2trJuRxfuUF9ZQnVpiue27sQ97ImdfkQ9x0+pxh3ufHILa3d0MbmmlInVpUyqKWV8ZTEdvYN092do7xngf/3meVq6BvjZX5/OuIpintzUztTaMipLUhSnEkysLqWtZ4BtHX0cPamKopyjy5aufh5a18y8qTXMGV8xfFpiU0sP37rnRabWlnHevEnMm1oz4jbd1Z/mp49t4vltO/ngaTNZt72LB9c1c/35x+xy+mBTSw9/eG4bp8wexwnRtFZv2YkZzJtaw8aW7uHXrySV4JH1Lfzk0U0UJY3jplTz7hOn0Z/O8nJzN3MaKujuT7OxpYe+wSzf//PLrNjYxsLptSx90yzOnzeZ4lRYxsFMljuf3MJvntnKuh1dfOYdR3PJwqmsb+piUk0pZUVJnn1lJ//99Cu0dA1w9ZlzeHBtEw+sbWbxzDoWz6pj7oQq6srD0VdH7yBt3YM8tK6ZlRtbuXjBFGaNr+CRl1qoLS9iSk0ZU+vKmFhdSiphrNneyRfuXM3KTW3Mrq/gmMlVLJ45jvefOoMv/tdqfvHEFj58xiz+9py5VJem+PGjG2nq7OfNcxs4eVYdmayzfEMb9dFr/tTmdrLupBIJsu48t3UngxnnzUfWc/yUmuGjo73JZJ2VG9uYVF3KjPryvQ57sCkICG+6B9c2c8nCKcNvuJ6BNKlEguJUIpxTBRKv45xqz0Ca0uj8+PrmLiZWl1JVWpT3+Dv7Brnt8c0cN6Wa0+fUk0gYm1t72Nzaw4kz63AP5+FryvOfZtyNdM79YBpIZ+kZSB9y571Hy9Ap0gPdSx0NA+nscDgNcXe6BzJU5nkq9o1AQSAiEnN7CwJ9fFREJOYUBCIiMacgEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjFX0CAws/PMbI2ZrTOz60foP8PM7jWzJ83saTN7ZyHrERGR1ypYEJhZErgROB84DnifmR2322BfAG5390XAFcD/LVQ9IiIyskIeEZwCrHP39e4+ANwKXLLbMA5UR49rgFcKWI+IiIygkEEwFdic87wx6pbrBuCDZtYI/Ab4+EgTMrNrzGyFma1oahr5F4BEROTAjPXF4vcBP3D3acA7gR+Z2Wtqcvdl7r7Y3Rc3NDSMepEiIm9khQyCLcD0nOfTom65PgrcDuDujwClwPgC1iQiIrspZBAsB+aa2WwzKyZcDL5rt2E2AecAmNmxhCDQuR8RkVFUsCBw9zRwHfB74HnCp4OeNbMvm9nF0WB/D1xtZk8BPwWW+OH2k2kiIoe5gv5gp7v/hnAROLfbF3MePwe8qZA1iIjI3o31xWIRERljCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCIiMRcQYPAzM4zszVmts7Mrh+h/7fMbFX096KZtReyHhERea1UoSZsZkngRuBcoBFYbmZ3uftzQ8O4+9/lDP9xYFGh6hERkZEV8ojgFGCdu6939wHgVuCSvQz/PuCnBaxHRERGUMggmApsznneGHV7DTObCcwG/rSH/teY2QozW9HU1HTQCxURibND5WLxFcAd7p4Zqae7L3P3xe6+uKGhYZRLExF5YytkEGwBpuc8nxZ1G8kV6LSQiMiYKGQQLAfmmtlsMysmNPZ37T6QmR0D1AGPFLAWERHZg4IFgbungeuA3wPPA7e7+7Nm9mUzuzhn0CuAW93dC1WLiIjsWcE+Pgrg7r8BfrNbty/u9vyGQtYgIiJ7d6hcLBYRkTGiIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMzlFQRm9gszu8DMFBwiIm8w+Tbs/xd4P7DWzL5uZkcXsCYRERlFeQWBu9/j7h8ATgQ2APeY2cNmttTMigpZoIiIFFbep3rMrB5YAlwFPAn8/4RguLsglYmIyKjI6/cIzOxO4GjgR8BF7r416nWbma0oVHEiEj+Dg4M0NjbS19c31qUclkpLS5k2bRpFRfmfrMn3h2m+7e73jtTD3RfnPTcRkX1obGykqqqKWbNmYWZjXc5hxd1paWmhsbGR2bNn5z1evqeGjjOz2qEnZlZnZh/b3yJFRPalr6+P+vp6hcABMDPq6+v3+2gq3yC42t3bh564extw9X7NSUQkTwqBA3cg6y7fIEhaztTNLAkU7/fcRETkkJPvNYLfES4Mfy96/ldRNxEROQDpdJpUKt8muLDyPSL4H8C9wF9Hf38EPluookRExtKll17KSSedxPHHH8+yZcsA+N3vfseJJ57IggULOOeccwDo6upi6dKlnHDCCcyfP5+f//znAFRWVg5P64477mDJkiUALFmyhGuvvZZTTz2Vz372szz++OOcfvrpLFq0iDPOOIM1a9YAkMlk+PSnP828efOYP38+3/nOd/jTn/7EpZdeOjzdu+++m8suu+ygLG9eceTuWeDfoj8RkVHx//33szz3ys6DOs3jplTzpYuO3+swN910E+PGjaO3t5eTTz6ZSy65hKuvvpoHHniA2bNn09raCsBXvvIVampqeOaZZwBoa2vb5/wbGxt5+OGHSSaT7Ny5kwcffJBUKsU999zDP/zDP/Dzn/+cZcuWsWHDBlatWkUqlaK1tZW6ujo+9rGP0dTURENDA9///vf5yEc+8vpXCPl/j2Au8DXgOKB0qLu7zzkoVYiIHEK+/e1vc+eddwKwefNmli1bxllnnTX8kcxx48YBcM8993DrrbcOj1dXV7fPaV9++eUkk0kAOjo6+PCHP8zatWsxMwYHB4ene+211w6fOhqa35VXXsmPf/xjli5dyiOPPMIPf/jDg7K8+Z6g+j7wJeBbwFuBpejOpSJSYPvacy+E++67j3vuuYdHHnmE8vJyzj77bBYuXMgLL7yQ9zRyP7mz+0c5Kyoqhh//4z/+I29961u588472bBhA2efffZep7t06VIuuugiSktLufzyyw/aNYZ8G/Myd/8jYO6+0d1vAC44KBWIiBxCOjo6qKuro7y8nBdeeIFHH32Uvr4+HnjgAV5++WWA4VND5557LjfeeOPwuEOnhiZOnMjzzz9PNpsdPrLY07ymTp0KwA9+8IPh7ueeey7f+973SKfTu8xvypQpTJkyha9+9assXbr0oC1zvkHQH92Ceq2ZXWdmlwGV+xpJRORwc95555FOpzn22GO5/vrrOe2002hoaGDZsmW8613vYsGCBbz3ve8F4Atf+AJtbW3MmzePBQsWcO+94QYMX//617nwwgs544wzmDx58h7n9dnPfpbPfe5zLFq0aLjRB7jqqquYMWMG8+fPZ8GCBdxyyy3D/T7wgQ8wffp0jj322IO2zObu+x7I7GTgeaAW+ApQDXzD3R89aJXkafHixb5ihW5vJPJG9fzzzx/URu6N5rrrrmPRokV89KMf3eMwI61DM1u5p1sC7fMEU/Tlsfe6+6eBLsL1ARERGWUnnXQSFRUVfPOb3zyo091nELh7xszefFDnKiIi+23lypUFmW6+l5yfNLO7gJ8B3UMd3f0XBalKRERGTb5BUAq0AH+R080BBYGIyGEu328W67qAiMgbVL7fLP4+4QhgF+5+cL7fLCIiYybf7xH8Cvh19PdHwsdHu/Y1kpmdZ2ZrzGydmV2/h2H+0syeM7NnzeyWkYYRERlNuTeNi4N8Tw39PPe5mf0UeGhv40QfO70ROBdoBJab2V3u/lzOMHOBzwFvcvc2M5uwn/WLiMjrdKD3C5oL7KvRPgVY5+7r3X0AuBW4ZLdhrgZujH7xDHffcYD1iIgcdO7OZz7zGebNm8cJJ5zAbbfdBsDWrVs566yzWLhwIfPmzePBBx8kk8mwZMmS4WG/9a1vjXH1+cv3GkEnu14j2Eb4jYK9mQpsznneCJy62zBHRdP/M5AEbnB3/eCNiAS/vR62PXNwpznpBDj/63kN+otf/IJVq1bx1FNP0dzczMknn8xZZ53FLbfcwjve8Q4+//nPk8lk6OnpYdWqVWzZsoXVq1cD0N7evo+pHzryPTVUVcD5zwXOBqYBD5jZCbm/jwxgZtcA1wDMmDGjQKWIiOzqoYce4n3vex/JZJKJEyfylre8heXLl3PyySfzkY98hMHBQS699FIWLlzInDlzWL9+PR//+Me54IILePvb3z7W5ect3yOCy4A/uXtH9LwWONvdf7mX0bYA03OeT4u65WoEHnP3QeBlM3uREAzLcwdy92XAMgj3GsqnZhF5A8hzz320nXXWWTzwwAP8+te/ZsmSJXzqU5/iQx/6EE899RS///3v+e53v8vtt9/OTTfdNNal5iXfawRfGgoBgGiP/Uv7GGc5MNfMZptZMXAFcNduw/yScDSAmY0nnCpan2dNIiIFdeaZZ3LbbbeRyWRoamrigQce4JRTTmHjxo1MnDiRq6++mquuuoonnniC5uZmstks7373u/nqV7/KE088Mdbl5y3fbxaPFBh7Hdfd02Z2HfB7wvn/m9z9WTP7MrDC3e+K+r3dzJ4DMsBn3L0l//JFRArnsssu45FHHmHBggWYGf/8z//MpEmTuPnmm/nGN75BUVERlZWV/PCHP2TLli0sXbqUbDYLwNe+9rUxrj5/+d6G+iagnfBxUIC/Aca5+5LClTYy3YZa5I1Nt6F+/fb3NtT5nhr6ODAA3Eb4GGgfIQxEROQwl++nhrqBEb8ZLCIih7e8jgjM7O7ok0JDz+vM7PeFK0tEREZLvqeGxud+tj/6JrBuByEiBZHPtUsZ2YGsu3yDIGtmw9/kMrNZjHA3UhGR16u0tJSWlhaFwQFwd1paWigtLd2v8fL9+OjngYfM7H7AgDOJvukrInIwTZs2jcbGRpqamsa6lMNSaWkp06ZN269x8r1Y/DszW0xo/J8kfBGsd78rFBHZh6KiImbPnj3WZcRKvreYuAr4BOE2EauA04BH2PWnK0VE5DCU7zWCTwAnAxvd/a3AIsIXzERE5DCXbxD0uXsfgJmVuPsLwNGFK0tEREZLvheLG6PvEfwSuNvM2oCNhStLRERGS74Xiy+LHt5gZvcCNYB+QEZE5A0g3yOCYe5+fyEKERGRsXGgv1ksIiJvEAoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYm5ggaBmZ1nZmvMbJ2ZXT9C/yVm1mRmq6K/qwpZj4iIvFaqUBM2syRwI3Au0AgsN7O73P253Qa9zd2vK1QdIiKyd4U8IjgFWOfu6919ALgVuKSA8xMRkQNQyCCYCmzOed4Yddvdu83saTO7w8ymjzQhM7vGzFaY2YqmpqZC1CoiEltjfbH4v4FZ7j4fuBu4eaSB3H2Zuy9298UNDQ2jWqCIyBtdIYNgC5C7hz8t6jbM3VvcvT96+h/ASQWsR0RERlDIIFgOzDWz2WZWDFwB3JU7gJlNznl6MfB8AesREZERFOxTQ+6eNrPrgN8DSeAmd3/WzL4MrHD3u4C/NbOLgTTQCiwpVD0iIjIyc/exrmG/LF682FesWDHWZYiIHFbMbKW7Lx6p31hfLBYRkTGmIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwpCEREYk5BICIScwoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQhERGJOQSAiEnMKAhGRmFMQiIjEnIJARCTmFAQiIjGnIBARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYk5BYGISMwVNAjM7DwzW2Nm68zs+r0M924zczNbXMh6RETktQoWBGaWBG4EzgeOA95nZseNMFwV8AngsULVIiIie5Yq4LRPAda5+3oAM7sVuJ0259cAAA13SURBVAR4brfhvgL8E/CZAtYCz9wBK38A42ZDNgu9bYCDezRA9N8SUNEA1VOgbBx0N4EZ1M+ForLQHyDTDxhUTQLPwkB3+CuphOIq6N4BloSK8TDhWBjshZaXIFUCdbOgfBx0N0NvO1ROgNLqXevNZmGwG0qqCrpaREQKGQRTgc05zxuBU3MHMLMTgenu/msz22MQmNk1wDUAM2bMOPCK0v2w5reQSIVGPjF0QGRDM4JMGhqXhwCAVxt+zx74fF/DoG4mtG14tVP11BAave3Q1w59OwGH2plQOwN2PA/ZdAiSVAmkSsNypPshMwDZTAih0hpIFkP7ZkgkoWZamH42E8bPpsOyJJJh2SwZLfdgGK9uFmQHw/J3t4TpVU18dR1kM2GepdVh2LpZoZbB3jBsIgUDXeF/qgQSRWF5BrpDkI47AsrqoGUdJIvCuF3bQw2lNWF5k0WvBmtpbVhXySIY7IP+zhCiWJjPUFB2bg3TT5VCui+MN/R6JqJlzMfQjsHehs8MhuFSxfm+4CKHtEIGwV6ZWQL4F2DJvoZ192XAMoDFixf7PgYf2QnvCX/5Sg+Eo4bycaHxa9sQjgLcAQ8NTjYNndtDQ1NcGRqi/s7QgFU2hGE7t8K21aFfwzGh0d72NGx7BhZdGRrqzq2w/Vno64DxR0NZbWjIikqhcWVoKI8+H4rKQyOX7g//h4OhNDRc/V1hGul+mHFqaLh3vgJYqDFVEhpos7BMngXPRI1a1ICuvy8MVzEeaqaGYHrlySg0ouBIlUDT87D65wc5IPfCEq/Oayi8smkoiY6k+nfuOnzZuLAMLS+F51WTYNL8cKTWsi5MI1kU1kciFQIlWRz6pfuhvD78mYV12tcetolEMgSQJcJrlywJoTjzjBA6bS+HbWWwd9d6iivCMO2b4eX7Q+21M0K33vawbGV14ShxoDuETLIkDNfbFl6nXEOBXF4fjijT/WEZSmvCMmYzUXj2hm1p/JGh20BXmN7Wp8Jyz31H6NbdBFgUgBaWr3pKWLamF0K3VEnYFisaYNycUHf3jvDfEmF+yeJXAz6Rgp7WV4epngLjjwrjDkTbaiIZdnoGe8O8hnYmOreFaZbWhPdDb1vYlhOpMI+hHaJktE33toUdmJIqGOgJy1E9Nay3zGB4/xWVRzsLJWH6O7eG9ZwqC+/zOWeH90Djimjbqgrrt68jvEeKK6C3NQxTUh2WY6h/SVVY5p7m6HWozX/n4xBg7gfWru5zwmanAze4+zui558DcPevRc9rgJeArmiUSUArcLG7r9jTdBcvXuwrVuyxt4ymzCB0bA4NYKokNJaeDafGsunwhskMhjdycUV4gzavCY3C+LlRY9YLlRMBC2/m9o3RNCrCG7enBdo3hekUl4fA7doe3phltaFhxaOQHQzzTBaFxqunDRqODm/I9s2h8atogAnHvFp/Nh3+D3SFxqj+iDDvnpZwROTZV4M5VRxO2ZXVhvFa14dl6NwajiKTJeHUY92sUGeunmbY+HBo7I+5IPTfvjo0OhUNoeaeVqioD41Muj/seFgyjJMs2nV6lggNYndzaMRTpdDfERqlyomhX7o/7Ex0N4caIazTkiqYcFzYadmyIoxbOXTUF+3oZDPQtS0sf0VDaGwHe0PodG4P8xo6jVpWF4bLDEZ//SE0s4OhX0VDaNB3boHWl18baomiUNdA56thnyiK6ki/OlxJTTSf6Ch41xUS7SxkGD7CZ3/bNjuAcfagpAamLNj1CLWsLmw7ZXVh+RKpsH1WTQqPa6aH18u9ICFiZivdfcQP5BTyiGA5MNfMZgNbgCuA9w/1dPcOYHxOkfcBn95bCMghJlkU9oqGzdz3OOOP3McAb3o9FY2d9EBYH3t7A2cz0VHVGOwpDvaGcEgkd+3e1xGCOzHC50YG+2CwJzoVl8M9hH5Jzcjj7U16IOw8lNaEv2z61SNa9xDI6YFX5znQHc0rOtoZks2GMMj0R6dFq8OyDfaEPXyPAjpRFF6XdF9YB4M9rwZa9bQwjXRfqGnt3eGIYdabwzT6O8MRQGlNeN2GTkumSsN6a3kp7LyU1oR+6V4oHx+WoXktbF0VjnZSJdD8Yhi2pzUE5Iiio67MAEw8HmacDtNPDdOvnAATT9j/9Z2ngh0RAJjZO4F/BZLATe7+P83sy8AKd79rt2HvI48g0BGBiBy23EMYZdMh8HY8G8IhMxCOlgZ7Qui88mQ4yhzseXXcigZ4x9dg/uUHNOuxOiLA3X8D/Ga3bl/cw7BnF7IWEZExZxZOPQ6pPHvPw2YGoWlNOGJpWReOWKqnFKSsMbtYLCIie5EsgknzwuNpi2HBFQWblW4xISIScwoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJOQWBiEjMKQhERGKuoLeYKAQzawI2HuDo44Hmg1jOwXSo1qa69o/q2n+Ham1vtLpmunvDSD0OuyB4PcxsxZ7utTHWDtXaVNf+UV3771CtLU516dSQiEjMKQhERGIubkGwbKwL2ItDtTbVtX9U1/47VGuLTV2xukYgIiKvFbcjAhER2Y2CQEQk5mITBGZ2npmtMbN1Znb9GNYx3czuNbPnzOxZM/tE1P0GM9tiZquiv3eOQW0bzOyZaP4rom7jzOxuM1sb/a8b5ZqOzlknq8xsp5l9cqzWl5ndZGY7zGx1TrcR15EF3462uafN7MRRrusbZvZCNO87zaw26j7LzHpz1t13R7muPb52Zva5aH2tMbN3FKquvdR2W05dG8xsVdR9VNbZXtqHwm5j7v6G/yP8ZvJLwBygGHgKOG6MapkMnBg9rgJeBI4DbiD8ZvNYrqcNwPjduv0zcH30+Hrgn8b4ddwGzByr9QWcBZwIrN7XOgLeCfwWMOA04LFRruvtQCp6/E85dc3KHW4M1teIr130PngKKAFmR+/Z5GjWtlv/bwJfHM11tpf2oaDbWFyOCE4B1rn7encfAG4FLhmLQtx9q7s/ET3uBJ4Hpo5FLXm6BLg5enwzcOkY1nIO8JK7H+g3y183d38AaN2t857W0SXADz14FKg1s8mjVZe7/8Hd09HTR4FphZj3/ta1F5cAt7p7v7u/DKwjvHdHvTYzM+AvgZ8Wav57qGlP7UNBt7G4BMFUYHPO80YOgcbXzGYBi4DHok7XRYd3N432KZiIA38ws5Vmdk3UbaK7b40ebwMmjkFdQ65g1zfmWK+vIXtaR4fSdvcRwp7jkNlm9qSZ3W9mZ45BPSO9dofS+joT2O7ua3O6jeo62619KOg2FpcgOOSYWSXwc+CT7r4T+DfgCGAhsJVwWDra3uzuJwLnA39jZmfl9vRwLDomnzc2s2LgYuBnUadDYX29xliuoz0xs88DaeAnUaetwAx3XwR8CrjFzKpHsaRD8rXbzfvYdadjVNfZCO3DsEJsY3EJgi3A9Jzn06JuY8LMiggv8k/c/RcA7r7d3TPungX+nQIeEu+Ju2+J/u8A7oxq2D50qBn93zHadUXOB55w9+1RjWO+vnLsaR2N+XZnZkuAC4EPRA0I0amXlujxSsK5+KNGq6a9vHZjvr4AzCwFvAu4bajbaK6zkdoHCryNxSUIlgNzzWx2tGd5BXDXWBQSnXv8T+B5d/+XnO655/UuA1bvPm6B66ows6qhx4QLjasJ6+nD0WAfBv5rNOvKscse2livr93saR3dBXwo+mTHaUBHzuF9wZnZecBngYvdvSene4OZJaPHc4C5wPpRrGtPr91dwBVmVmJms6O6Hh+tunK8DXjB3RuHOozWOttT+0Cht7FCXwU/VP4IV9dfJCT558ewjjcTDuueBlZFf+8EfgQ8E3W/C5g8ynXNIXxi4yng2aF1BNQDfwTWAvcA48ZgnVUALUBNTrcxWV+EMNoKDBLOx350T+uI8EmOG6Nt7hlg8SjXtY5w/nhoO/tuNOy7o9d4FfAEcNEo17XH1w74fLS+1gDnj/ZrGXX/AXDtbsOOyjrbS/tQ0G1Mt5gQEYm5uJwaEhGRPVAQiIjEnIJARCTmFAQiIjGnIBARiTkFgcgoMrOzzexXY12HSC4FgYhIzCkIREZgZh80s8eje89/z8ySZtZlZt+K7hP/RzNriIZdaGaP2qv3/R+6V/yRZnaPmT1lZk+Y2RHR5CvN7A4LvxXwk+jbpCJjRkEgshszOxZ4L/Amd18IZIAPEL7hvMLdjwfuB74UjfJD4H+4+3zCtzuHuv8EuNHdFwBnEL7FCuGOkp8k3Gd+DvCmgi+UyF6kxroAkUPQOcBJwPJoZ72McJOvLK/eiOzHwC/MrAaodff7o+43Az+L7ts01d3vBHD3PoBoeo97dB8bC7+ANQt4qPCLJTIyBYHIaxlws7t/bpeOZv+423AHen+W/pzHGfQ+lDGmU0Mir/VH4D1mNgGGfy92JuH98p5omPcDD7l7B9CW80MlVwL3e/h1qUYzuzSaRomZlY/qUojkSXsiIrtx9+fM7AuEX2tLEO5O+TdAN3BK1G8H4ToChNsCfzdq6NcDS6PuVwLfM7MvR9O4fBQXQyRvuvuoSJ7MrMvdK8e6DpGDTaeGRERiTkcEIiIxpyMCEZGYUxCIiMScgkBEJOYUBCIiMacgEBGJuf8HtRdmZP+jSnQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT1ZZjTC32NO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06db8dd9-bc5c-40f0-d290-b79e05a773f2"
      },
      "source": [
        "#Note : An alternative to using train_test_split() is to specify a validation_split percentage.\n",
        "#This is done when fitting the model, for example:\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "history = model.fit(X,y, verbose = 1,\n",
        "                    validation_split = 0.2, # split data in 80-20 sets\n",
        "                    epochs = 100,\n",
        "                    batch_size = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3852 - accuracy: 0.8440 - val_loss: 0.3897 - val_accuracy: 0.8370\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3799 - accuracy: 0.8436 - val_loss: 0.3812 - val_accuracy: 0.8400\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3690 - accuracy: 0.8515 - val_loss: 0.3661 - val_accuracy: 0.8465\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3540 - accuracy: 0.8564 - val_loss: 0.3535 - val_accuracy: 0.8565\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8612 - val_loss: 0.3483 - val_accuracy: 0.8550\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8621 - val_loss: 0.3456 - val_accuracy: 0.8575\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3382 - accuracy: 0.8640 - val_loss: 0.3424 - val_accuracy: 0.8605\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.8630 - val_loss: 0.3433 - val_accuracy: 0.8580\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.8631 - val_loss: 0.3421 - val_accuracy: 0.8600\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3356 - accuracy: 0.8650 - val_loss: 0.3410 - val_accuracy: 0.8580\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8631 - val_loss: 0.3411 - val_accuracy: 0.8595\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3356 - accuracy: 0.8637 - val_loss: 0.3417 - val_accuracy: 0.8565\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8627 - val_loss: 0.3405 - val_accuracy: 0.8605\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8654 - val_loss: 0.3409 - val_accuracy: 0.8585\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8652 - val_loss: 0.3396 - val_accuracy: 0.8580\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8629 - val_loss: 0.3430 - val_accuracy: 0.8545\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8629 - val_loss: 0.3402 - val_accuracy: 0.8600\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.8654 - val_loss: 0.3420 - val_accuracy: 0.8600\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.8640 - val_loss: 0.3397 - val_accuracy: 0.8565\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3343 - accuracy: 0.8648 - val_loss: 0.3412 - val_accuracy: 0.8570\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.8637 - val_loss: 0.3404 - val_accuracy: 0.8610\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8635 - val_loss: 0.3426 - val_accuracy: 0.8595\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3339 - accuracy: 0.8645 - val_loss: 0.3401 - val_accuracy: 0.8565\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8651 - val_loss: 0.3420 - val_accuracy: 0.8565\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3339 - accuracy: 0.8641 - val_loss: 0.3382 - val_accuracy: 0.8620\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8645 - val_loss: 0.3410 - val_accuracy: 0.8585\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8654 - val_loss: 0.3429 - val_accuracy: 0.8575\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8636 - val_loss: 0.3398 - val_accuracy: 0.8585\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3339 - accuracy: 0.8631 - val_loss: 0.3393 - val_accuracy: 0.8625\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3339 - accuracy: 0.8645 - val_loss: 0.3408 - val_accuracy: 0.8560\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3339 - accuracy: 0.8650 - val_loss: 0.3406 - val_accuracy: 0.8555\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8650 - val_loss: 0.3471 - val_accuracy: 0.8580\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8651 - val_loss: 0.3405 - val_accuracy: 0.8595\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3343 - accuracy: 0.8645 - val_loss: 0.3416 - val_accuracy: 0.8595\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8646 - val_loss: 0.3407 - val_accuracy: 0.8615\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3339 - accuracy: 0.8650 - val_loss: 0.3439 - val_accuracy: 0.8560\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3338 - accuracy: 0.8651 - val_loss: 0.3410 - val_accuracy: 0.8555\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8635 - val_loss: 0.3404 - val_accuracy: 0.8605\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3331 - accuracy: 0.8649 - val_loss: 0.3397 - val_accuracy: 0.8605\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8627 - val_loss: 0.3399 - val_accuracy: 0.8580\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3342 - accuracy: 0.8634 - val_loss: 0.3393 - val_accuracy: 0.8575\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8649 - val_loss: 0.3394 - val_accuracy: 0.8605\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8636 - val_loss: 0.3396 - val_accuracy: 0.8585\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3336 - accuracy: 0.8630 - val_loss: 0.3425 - val_accuracy: 0.8560\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8651 - val_loss: 0.3423 - val_accuracy: 0.8570\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.8652 - val_loss: 0.3401 - val_accuracy: 0.8585\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8652 - val_loss: 0.3418 - val_accuracy: 0.8585\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8627 - val_loss: 0.3413 - val_accuracy: 0.8565\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8626 - val_loss: 0.3396 - val_accuracy: 0.8595\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8640 - val_loss: 0.3387 - val_accuracy: 0.8600\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8662 - val_loss: 0.3383 - val_accuracy: 0.8585\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.8658 - val_loss: 0.3402 - val_accuracy: 0.8600\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3342 - accuracy: 0.8643 - val_loss: 0.3407 - val_accuracy: 0.8600\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8645 - val_loss: 0.3429 - val_accuracy: 0.8550\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3337 - accuracy: 0.8643 - val_loss: 0.3408 - val_accuracy: 0.8565\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8648 - val_loss: 0.3385 - val_accuracy: 0.8600\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3336 - accuracy: 0.8641 - val_loss: 0.3402 - val_accuracy: 0.8600\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3331 - accuracy: 0.8660 - val_loss: 0.3386 - val_accuracy: 0.8590\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3337 - accuracy: 0.8645 - val_loss: 0.3382 - val_accuracy: 0.8600\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8649 - val_loss: 0.3401 - val_accuracy: 0.8580\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.8652 - val_loss: 0.3402 - val_accuracy: 0.8605\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.8655 - val_loss: 0.3395 - val_accuracy: 0.8565\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.8634 - val_loss: 0.3405 - val_accuracy: 0.8575\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8634 - val_loss: 0.3420 - val_accuracy: 0.8585\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3336 - accuracy: 0.8655 - val_loss: 0.3404 - val_accuracy: 0.8580\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.8629 - val_loss: 0.3428 - val_accuracy: 0.8600\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.8626 - val_loss: 0.3391 - val_accuracy: 0.8610\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8660 - val_loss: 0.3396 - val_accuracy: 0.8620\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3340 - accuracy: 0.8650 - val_loss: 0.3399 - val_accuracy: 0.8585\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3329 - accuracy: 0.8659 - val_loss: 0.3470 - val_accuracy: 0.8585\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8658 - val_loss: 0.3407 - val_accuracy: 0.8575\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8650 - val_loss: 0.3390 - val_accuracy: 0.8610\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8649 - val_loss: 0.3424 - val_accuracy: 0.8585\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8651 - val_loss: 0.3401 - val_accuracy: 0.8580\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8654 - val_loss: 0.3407 - val_accuracy: 0.8605\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8650 - val_loss: 0.3396 - val_accuracy: 0.8585\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3326 - accuracy: 0.8652 - val_loss: 0.3435 - val_accuracy: 0.8535\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8631 - val_loss: 0.3414 - val_accuracy: 0.8595\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8649 - val_loss: 0.3398 - val_accuracy: 0.8610\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3333 - accuracy: 0.8652 - val_loss: 0.3422 - val_accuracy: 0.8570\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8625 - val_loss: 0.3401 - val_accuracy: 0.8560\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8645 - val_loss: 0.3401 - val_accuracy: 0.8600\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8640 - val_loss: 0.3386 - val_accuracy: 0.8595\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8651 - val_loss: 0.3384 - val_accuracy: 0.8590\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8650 - val_loss: 0.3407 - val_accuracy: 0.8580\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3331 - accuracy: 0.8643 - val_loss: 0.3403 - val_accuracy: 0.8600\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8658 - val_loss: 0.3435 - val_accuracy: 0.8590\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8658 - val_loss: 0.3408 - val_accuracy: 0.8550\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3330 - accuracy: 0.8648 - val_loss: 0.3401 - val_accuracy: 0.8595\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.8640 - val_loss: 0.3402 - val_accuracy: 0.8565\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.8655 - val_loss: 0.3391 - val_accuracy: 0.8570\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3320 - accuracy: 0.8644 - val_loss: 0.3415 - val_accuracy: 0.8575\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8640 - val_loss: 0.3399 - val_accuracy: 0.8615\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3334 - accuracy: 0.8649 - val_loss: 0.3396 - val_accuracy: 0.8570\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8648 - val_loss: 0.3405 - val_accuracy: 0.8560\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3330 - accuracy: 0.8658 - val_loss: 0.3392 - val_accuracy: 0.8590\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3332 - accuracy: 0.8654 - val_loss: 0.3429 - val_accuracy: 0.8565\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3330 - accuracy: 0.8650 - val_loss: 0.3407 - val_accuracy: 0.8585\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 0.3333 - accuracy: 0.8660 - val_loss: 0.3415 - val_accuracy: 0.8585\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 0.3323 - accuracy: 0.8659 - val_loss: 0.3399 - val_accuracy: 0.8595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "utkusz6X6SvB",
        "outputId": "ae35df01-4fa8-4805-aa6c-e9fa15c7f5de"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['accuracy','validation_accuracy', 'loss', 'validation_loss'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxU9bn48c8zeyb7BiEhkKDssoTdBcFSFxRBUcTWDaz606qIve291NpWrb3tvbW2tbX20lat1rVYlLYqFUVBQQRkX5QtkABZyL7MTGb5/v44Q0wgQEBCwHner1demTnne855zvZ9zjbfI8YYlFJKxS5bZweglFKqc2kiUEqpGKeJQCmlYpwmAqWUinGaCJRSKsZpIlBKqRiniUDFBBHJExEjIo52lJ0hIh+eiriUOh1oIlCnHREpFJEmEck4pPuaaGWe1zmRtYolQUTqReStzo5FqS9LE4E6Xe0CvnHwi4gMArydF85hrgECwMUiknUqJ9yesxqljocmAnW6eh64ucX3W4DnWhYQkWQReU5EykVkt4g8KCK2aD+7iDwmIgdEZCdwRRvD/llE9ovIXhF5VETsxxHfLcAfgPXAjYeM+wIRWSYi1SJSJCIzot3jROSX0VhrROTDaLfxIlJ8yDgKReTr0c8Picg8EfmriNQCM0RklIgsj05jv4j8TkRcLYYfKCLviEiliJSKyAMikiUijSKS3qLcsOjycx7HvKuvGE0E6nT1MZAkIv2jFfT1wF8PKfNbIBnoBYzDShwzo/1uByYBBcAI4NpDhn0WCAFnR8tcAtzWnsBEpCcwHngh+nfzIf3eisaWCQwF1kZ7PwYMB84D0oD/BCLtmSYwBZgHpESnGQbuBzKAc4EJwLejMSQCi4C3gezoPL5rjCkB3geuazHem4CXjTHBdsahvoqMMfqnf6fVH1AIfB14EPgZcBnwDuAADJAH2IEmYECL4f4f8H7083vAnS36XRId1gF0xbqsE9ei/zeAxdHPM4APjxLfg8Da6OccrEq5IPr9+8D8NoaxAT5gSBv9xgPFbS2D6OeHgCXHWGazD043Oi9rjlBuOvBR9LMdKAFGdfY617/O/dNrjep09jywBMjnkMtCWEfCTmB3i267sSpmsI6Eiw7pd1DP6LD7ReRgN9sh5Y/mZuCPAMaYvSLyAdalojVALrCjjWEyAM8R+rVHq9hEpA/wONbZjhcrwa2O9j5SDABvAH8QkXygL1BjjPnkBGNSXxF6aUidtowxu7FuGl8O/P2Q3geAIFalflAPYG/0836sCrFlv4OKsM4IMowxKdG/JGPMwGPFJCLnAb2B74tIiYiUAKOBb0Zv4hYBZ7Ux6AHAf4R+DbS4ER69FJZ5SJlDmwl+CtgK9DbGJAEPAAezWhHW5bLDGGP8wKtY9zVuwkq2KsZpIlCnu28BXzPGNLTsaIwJY1VoPxWRxOi1+e/wxX2EV4FZItJdRFKBOS2G3Q/8G/iliCSJiE1EzhKRce2I5xasy1QDsK7/DwXOAeKAiVjX778uIteJiENE0kVkqDEmAjwNPC4i2dGb2eeKiBv4HPCIyBXRm7YPAu5jxJEI1AL1ItIPuKtFv38C3URktoi4o8tndIv+z2Fd/pqMJgKFJgJ1mjPG7DDGrDpC73uxjqZ3Ah8CL2JVtmBdulkIrAM+5fAzipsBF7AZqMK6EdvtaLGIiAfrRutvjTElLf52YVWotxhj9mCdwfwHUIl1o3hIdBTfBTYAK6P9/gewGWNqsG70/gnrjKYBaPUUURu+C3wTqIvO6ysHexhj6oCLgSux7gFsAy5q0f8jrJvUn0bPulSME2P0xTRKxRoReQ940Rjzp86ORXU+TQRKxRgRGYl1eSs3evagYpxeGlIqhojIX7B+YzBbk4A6SM8IlFIqxukZgVJKxbgz7gdlGRkZJi8vr7PDUEqpM8rq1asPGGMO/X0KcAYmgry8PFatOtLThEoppdoiIkd8VFgvDSmlVIzTRKCUUjFOE4FSSsU4TQRKKRXjNBEopVSM00SglFIxThOBUkrFuDPudwRnikjEarrDZpNjlLT4g2EKKxqwiWC3CYkeB10SPUcdf1FVIxkJbuLdJ74ajTHUBUI4bTbiXG2/uz0YjlBeFyAUNuSmxdHirV5HHa8/GMFE36diDISNIRw2hI0hwe3A42x7esYYAqEIwXCEcMQQihgSPQ7cjuN5t/zxqWkM4guGCUWsaR4kCNkpHhz2Yx8zFVU28uH2A1TUB0j0OEn0OOia5KFfViLpCcd6vUDbguEIW/bX8llJHTmpcfTPSiI1vvkd9c3LubEpRGNTGH8wTCAUIRCK0CPNS2bikae7r9qHAXJS4o5YZltpHWuKquma5CEnJY60eBfldQFKav1UNgSwiWATwWm3kRbvIiPBRXqCG7fDhsNmbcvBsCEQ+iKuQDBMUziCw2Yj3m3H67K230AoTCAYIT3B1dzt0GXRGAjTGAzhdTpI9jrbtQwjEUO1z3ols90muOw2PE5b83ZsjGFvtY9tpfUEQuHm4VK9LnJS48hKOnz9h8IRCisaiRhDbqr3iPvOocIRQ3ldgL3VjVTUN+Fx2vG6rGXgddnxuu247DZKa60yJTUBDCa6LG0U9EjhrMyEdk3reGgiaKdQOMLWkjo+3VPF+uIa3A4bOalx5KTE4XbYoxVWhB1l9azeU8XaPdXYbEJBj1SG90ila5KbqsYg1Y1NAGSnxJGdEkdDIMS/N5fw/mflNDaFW03z7C4JjO+TyblnpRMXrTRr/UE++Lycd7eUUVYXAKwduVdmPIFghPL6AJUNTSTHOclJiSMnNY5EjwOXw4bbbqPaF2RftY/iKh8H6puobmwiFK340uJdZKd4SHA78DWFaWwKU+0LcqA+wMEmqZLjnAzunsyAbkkke50kuh24Iz4+rzJsK6unsKKB6sYg9YFQqwq1LXFOO6leJzabEI4Yq8IIhmkMhg8b1mET+nRN5JycJDxOO9tK69lWVocxMCo/jXPPSqd3l0RqfNYy3l/jZ2tJLVtL6iit9ZOb6iU/I568jHjS4l2kep047TZW765i+c4KdpY3HCFKSPE6uahvFyb070KPNG9zsi6p9bO9tJ7PS+tYWVhJYUXjEceRmegmOyWOYChCIBQmYsBlt+GOVkj1/iC1/hD+YJjkOCepXhcOu7Blfy3+YOv322ckuBGBxkCIxmCYozUX1qdrAuedlUH31C8q+x3l9SzbUcHuaLz9uyVx6cCujMpLw+Oy43bY2F5Wzwsr9vDJrsqjrcIO4bAJQ3NTOPesdDxOO+uLq1lXVENJrb+5jE1gTK90Jg7qxoBuiazZU82KXZXsKK8nwe0gyePEYRf2VvnYU9lIINR6GbodNjIS3CTHOSmqbKQuEDpiPDaxlnlGgpuMRDdVDU18XlrXapxdEt10TfJEK3U7YQOlNX5Kav3U+oPYo9vMwQObE/XTq8/pkERwxjU6N2LECHMqflm8vayOP3ywk90VDZTU+imtDdAUiuAhwETvZ+wzaazw5fDF2wEN3agkIC66dcthWI9UQhHDp7ur+DxaYQG4HNaRRVMoQk8pobfspcg7gOED+zI6P615YymrDbBkWzkrdlbSFI40T+Ms2UeaK8ywHikM6pHBLunBtvJGdh1owOuyk5HoJj3eRXVjkNrKEkZU/gtfGDaFe7Ah2J0mTzo5KXF0T40jM9FNqtdFqtdFUzhCXfkeJux6nNRQKUsTJrI29RI83iS6JnvISvIgAuuLa1hXVM22slouNKu5x/EGg2Qnv4jcwNL06+jVJYG0eBeJHgfxbgf2FmcPdpvgsAk2gTp/kKqGJmob/WT7t3G2bx09fVvYmziEjd2nE+e2jirt0aPKkho/G/fV4iveQL/wNrokWTtejS2VF0t7sKu29XYsAvnp8VyQ0cAgeyGfNvVkZXUCe6p8NLXYgRPcDkbmpTIqP50Ur9OanggHww6GI6zYWcniz8qoagy2mIIhHj9JNNIjPkRutywG9uvH2D6Z5KZ5qfMFaThQRGXZXgoPNLDrQAM7A4n43Zm4nTZsIjSFwjSFIoQNJHocJLuF3OAeGv0Bav1BfCHIyMljQK88+nVLZn91IzuLiinfX0SNJxuXJ775aDLF1khu3Vr8qf2IJOfitNvYWlLHsh0HWFlY2SqZJHocjM5P59yz0olEDAs3lbB9TxF9KSJHysmRA+TIAc5yVdHbXYXXZaMsfyrru06hJJxMZqKbrGQP6dEzk3DEOoOrbGiiae96Uvf8m3LvWRQmj8YncdZBiMPW/D/e+MiqWoXPkcg+7wDqQlYydDtsuOw2dlU0sGxHBRuKq+hiKhmXXMoFSaUkJqWwO/dq3N5E9lb7+NeG/a0SeK80F+PSqqmNuClrclET8ZCVkkDPdC/ZKXHYRAhFDE2hCJUNASrqfLhqC0lJTaN79zz6dksmIXp2HTGGivom9lX72Fvto6w2wIH6AOX1ARI9DvpnJdGvWxJOu1BU2cjuikbK6wM4fBVcUvd3kkwdSzK/iT29FyleJxFjJQCHTeiWbB2gZcS7CYSsA66GgHVG1xgMEwiGrTOwg2cjNivucChIssdGUsKJJQIRWW2MGdFmP00ErdX6g/xm0Tb+sqwQj9POgOwkshMdjJbNnO97j+4li7A11QMQScqhrvtF0FSPt+QTnPX7rJFk9oee54LdDaUbiZRsJOL0Ys65BsfQb2AiEZre/wXuzxcgJrqDpveG7AKISwVPMiR1gwFX0WBPYsv+Wmz1JeR//ANSi99rHXBaLxh5Gwy9AeJSIByC2r3wyVxY9TQEDzlK7TIABl8Hg6ZBcnermzGw9gV4+wEIN0FaPpRtBncy9LvCmkZKLrjioWYv1BRhdi5GSjcRTu5BMDkPz54lMPBqmPw7cLfYUI2BA5/D9kVQsgFKNsKBz6zpHCqxG9Tth+4jYcrvIbPPF/18VfDeT2HVn8G0ProzDg++7hdQmjYCZ0I6cUlpJIWqcW76GxR9/EXBpO6YnucRyJ/AgawL8dkTyc+Ix2ETqC+z5rl0I5RvhVA0PhHI7Es49zzWm3yCezfQtfANsorexB2oaB1/XCp0Pcf6XLoJfIccTdtdcN4sGPsf4PJ+0b2hAtY8Byv/DDVFHMYZDwmZ0HAAotsedhfkDIfsYVC6AXYvg0gIbA4YPB0uuN9ab/WlhCp301S5G1tNMbbaIhwmhC0uBdxJUF9qDVu+pdUkmzwZONN6Iim51rLf9QHYnHD218GdaBWyOaztNDkX7E5Y8wLsWdZ6fnueD6l51jbtjIM9H0PhhxCJJlW721rfQ663tmFb9BJMxQ7Cr92Ofd/qw5fx6Ltg5G0Ybxqfldaxp7SKMbVvk7T6d1C9p3V5VyJ4ksCTAsk5VqxxqbB/HRStgEDtF7Em58LAq2DMtyE+w9qX1r4ASx+zxtO83+RAJAJNdeCvBX+N9bflH7D6WQj5weG21seIW631nZhlTccY2LcG1r9ixdDzPOh7OXQbam13e5Zb/cPR5RMJQV2JtV3U7oMrfwPDbjp8G2kHTQTtEIkY3n3vbbp/+AAVkTjoMpCCwUOJL1sN2xZBoMbaGAZMgXOmWivl87dhx3vWDtXzXOhxrrWj7l4Ge1aACVsVb9eB1srcvsjqBuBKgJHfgt6XwN7V1jClm60NKlALGHDEwaBrreHf/5lVOY37npVowKpoPn3equzsLmtHDUaPkMRuDXvBd6yNunSTteFt/ae1AyCQ0MX6HwlB4wFrp538W6sCKVoBn/zRqgAaylsvLEccZPaFMXfBOdeCzQ4f/QbefRhSeloJzZNsVaI7FkPVLmu4xG7WvHTpby1LsMpk9LF2iPhM2PgavPk9aGqwKp24FHB6YdN8a35H3gaj77QqHoCK7fDZ2/D5W4dXAhl9Ych06HkBlKyH3R/BrqXWvIodug2BQB3UFEPI98Vw8V2spAfWsjlYOYvdWn92N/S9zKqIPSlWxdhYYSWR0k3Wzt51oJUUkg+eNRrYvADWvwzJPWDkrVBdZJXftwbCAci/EIZ801p2YCXL2n3W9OtLreWTnGv9L91obTP710L62dDnMug1Dj7/9xeVkc3xRYV7UFyaVUn5a61txZUIuaOs7Td7mLX+kruD85D7Uwe2wco/WdtwJLoNh4NW4j64TafmWetn8PVWsv/sLWv915da23S46YtY+1xqxbBnubUPlW2GnBFwxS+hbAu8+V0r/gu/Zy3nLv2tGJb+0lrXYC2n5B7W9llfYg0/YqbV72AFHai1PvsqrfVcU2Qltsx+1v7afaR1sFS9x5ru9kVWwhpyPRR+ZM1HzghrOy1eaa1Ld9IX+2hLLZOwOxHe/zl8+py1fNzJ1sFU0AeVO6z9tUt/68DIhKPrKnT49ic2K4kk51rrpf8ka/86AZoIjmHNniqeeH0JP6+YhdNuw5Oei7fqc6tyiM+E3pdaO/7ZX7c2kpYiYWtlHXoDNRI9arW1uMlUXw6b/m7tpAU3gTet7YAiESjbZO1461+1NtQe58KUJyH9rMPL719nlQNr5/AkQ++LrQq9LZU7YcNrrY8+c4ZbMdnauCka9FlnAk111gbpTT98fgF2fgCL/9vaMQO1EApA7mhr2fW57IszkGOpL4N3fmxVcv5aa1xdz4GJP7cq77YYA/7qL8rbXVaCOWy9hGHvp1ZlsmeFtQ5Selh/mf2s6cSntx6mocKqsIpXWst0wBQrQZ2Iwo+sSu7gGVfXgZAzDAputCqG4xUJW4m4pfpyWP2Mtd6Su1vzdrAiaXm2Fg5Zy+fQ4Y9HOGQlA1+VNS9HG1eoCRyuw7sbA+tehnd++MVBR8/zYerctreZkg2w/V1r+60usqY5+v9B/ri2t8vDYg5+cSBxqPLPYOnjsOFv1pnxhB9D/yut8VbssA5UGiusZOBJjp5tJFvfM/tCUnbr8R3YBp+9acVZU2wlwwGTYcBV1jbUWGkln31rodtg64Aopcex5+EEaCI4ij8t3clj/1rL/LhHOdu2H8cdi5CuA60drG4/JGa3XTmeKr4qKNtqVaidGYc6eSJhq8JL6Nq+iitW+KqtI35vOpx375dLUF9WoM4687V/dZ6nOVoi+OrM5XEyxvCbd7fx60WfMy/jL/Sr34lc95J1VAPWRtjeI9iOFJdqnbarrw6b/YtrxuoLcSlwyU86OwrLwfsgMSJmEsGeikZ2VzbgdTmId9uZt6qYlz7czBtdnmdI7fvw9Yeh78TODlMppU65mEkEb27cz8/f2tr8/SzZy/vJvyOjrggufsR6mkMppWJQzCSCqQU5DO+ZiinbQvqO+fTc8SJ2exxy8xvW0xpKKRWjYiYRdNn7Dl0++B/riQOxW0+xXP6L6ON9SikVu2ImERD0W8/ZT/xfGDjV+oGOUkqpGEoEg66FwdM6OwqllDrtxM6D6fq8tlJKtSl2EoFSSqk2aSJQSqkYp4lAKaVinCYCpZSKcZoIlFIqxmkiUEqpGKeJQCmlYpwmAqWUinEdmghE5DIR+UxEtovInDb69xCRxSKyRkTWi8jlHRmPUkqpw3VYIhARO/AkMBEYAHxDRAYcUuxB4FVjTAFwPfD7jopHKaVU2zryjGAUsN0Ys9MY0wS8DEw5pIwBkqKfk4F9HRiPUkqpNnRkIsgBWrwdneJot5YeAm4UkWLgTeDetkYkIneIyCoRWVVeXt4RsSqlVMzq7JvF3wCeNcZ0By4HnheRw2Iyxsw1xowwxozIzNTmo5VS6mTqyESwF8ht8b17tFtL3wJeBTDGLAc8QEYHxqSUUuoQHZkIVgK9RSRfRFxYN4MXHFJmDzABQET6YyUCvfajlFKnUIclAmNMCLgHWAhswXo6aJOIPCIik6PF/gO4XUTWAS8BM4wxpqNiUkopdbgOfUOZMeZNrJvALbv9qMXnzcD5HRmDUkqpo+vsm8VKKaU6mSYCpZSKcZoIlFIqxmkiUEqpGKeJQCmlYpwmAqWUinGaCJRSKsZpIlBKqRiniUAppWKcJgKllIpxmgiUUirGaSJQSqkYp4lAKaVinCYCpZSKcZoIlFIqxmkiUEqpGKeJQCmlYpwmAqWUinGaCJRSKsZpIlBKqRiniUAppWKcJgKllIpxmgiUUirGaSJQSqkYp4lAKaVinCYCpZSKcZoIlFIqxmkiUEqpGNehiUBELhORz0Rku4jMaaP/r0RkbfTvcxGp7sh4lFJKHc7RUSMWETvwJHAxUAysFJEFxpjNB8sYY+5vUf5eoKCj4lFKKdW2jjwjGAVsN8bsNMY0AS8DU45S/hvASx0Yj1JKqTZ0ZCLIAYpafC+OdjuMiPQE8oH3jtD/DhFZJSKrysvLT3qgSikVy06Xm8XXA/OMMeG2ehpj5hpjRhhjRmRmZp7i0JRS6qutIxPBXiC3xffu0W5tuR69LKSUUp2iIxPBSqC3iOSLiAursl9waCER6QekAss7MBallFJH0GGJwBgTAu4BFgJbgFeNMZtE5BERmdyi6PXAy8YY01GxKKWUOrIOe3wUwBjzJvDmId1+dMj3hzoyBqW+ioLBIMXFxfj9/s4ORZ1mPB4P3bt3x+l0tnuYDk0ESqmOUVxcTGJiInl5eYhIZ4ejThPGGCoqKiguLiY/P7/dw50uTw0ppY6D3+8nPT1dk4BqRURIT08/7jNFTQRKnaE0Cai2nMh2oYlAKaVinCYCpZSKcZoIlFKntVAo1NkhfOXpU0NKneEe/scmNu+rPanjHJCdxI+vHHjMcldddRVFRUX4/X7uu+8+7rjjDt5++20eeOABwuEwGRkZvPvuu9TX13PvvfeyatUqRIQf//jHXHPNNSQkJFBfXw/AvHnz+Oc//8mzzz7LjBkz8Hg8rFmzhvPPP5/rr7+e++67D7/fT1xcHM888wx9+/YlHA7zX//1X7z99tvYbDZuv/12Bg4cyBNPPMHrr78OwDvvvMPvf/975s+ff1KX0VeJJgKl1Al7+umnSUtLw+fzMXLkSKZMmcLtt9/OkiVLyM/Pp7KyEoCf/OQnJCcns2HDBgCqqqqOOe7i4mKWLVuG3W6ntraWpUuX4nA4WLRoEQ888ACvvfYac+fOpbCwkLVr1+JwOKisrCQ1NZVvf/vblJeXk5mZyTPPPMOtt97aocvhTKeJQKkzXHuO3DvKE0880XykXVRUxNy5c7nwwgubn2FPS0sDYNGiRbz88svNw6Wmph5z3NOmTcNutwNQU1PDLbfcwrZt2xARgsFg83jvvPNOHA5Hq+nddNNN/PWvf2XmzJksX76c55577iTN8VeTJgKl1Al5//33WbRoEcuXL8fr9TJ+/HiGDh3K1q1b2z2Olo86Hvrse3x8fPPnH/7wh1x00UXMnz+fwsJCxo8ff9Txzpw5kyuvvBKPx8O0adOaE4Vqm94sVkqdkJqaGlJTU/F6vWzdupWPP/4Yv9/PkiVL2LVrF0DzpaGLL76YJ598snnYg5eGunbtypYtW4hEIke9hl9TU0NOjvU6k2effba5+8UXX8z//d//Nd9QPji97OxssrOzefTRR5k5c+bJm+mvqHYlAhH5u4hcISKaOJRSAFx22WWEQiH69+/PnDlzGDNmDJmZmcydO5epU6cyZMgQpk+fDsCDDz5IVVUV55xzDkOGDGHx4sUA/PznP2fSpEmcd955dOvW7YjT+s///E++//3vU1BQ0Oopottuu40ePXowePBghgwZwosvvtjc74YbbiA3N5f+/ft30BL46pD2NPopIl8HZgJjgL8BzxhjPuvg2No0YsQIs2rVqs6YtFKnjS1btmgFdwz33HMPBQUFfOtb3+rsUE65trYPEVltjBnRVvl2HeEbYxYZY24AhgGFwCIRWSYiM0Wk/U3cKaXUKTB8+HDWr1/PjTfe2NmhnBHafQdFRNKBG4GbgDXAC8AFwC3A+I4ITimlTsTq1as7O4QzSrsSgYjMB/oCzwNXGmP2R3u9IiJ6nUYppc5g7T0jeMIYs7itHke65qSUUurM0N6ngAaISMrBLyKSKiLf7qCYlFJKnULtTQS3G2OqD34xxlQBt3dMSEoppU6l9iYCu7T4CaCI2AFXx4SklPoqSkhIAGDfvn1ce+21bZYZP348x3o8/Ne//jWNjY3N3y+//HKqq6uPMoQ6lvYmgrexbgxPEJEJwEvRbkopdVyys7OZN2/eCQ9/aCJ48803SUlJOcoQp6fTqXnt9t4s/i/g/wF3Rb+/A/ypQyJSSh2ft+ZAyYaTO86sQTDx50ctMmfOHHJzc7n77rsBeOihh3A4HCxevJiqqiqCwSCPPvooU6ZMaTVcYWEhkyZNYuPGjfh8PmbOnMm6devo168fPp+vudxdd93FypUr8fl8XHvttTz88MM88cQT7Nu3j4suuoiMjAwWL15MXl4eq1atIiMjg8cff5ynn34asH51PHv2bAoLC5k4cSIXXHABy5YtIycnhzfeeIO4uLg25+uPf/wjc+fOpampibPPPpvnn38er9dLaWkpd955Jzt37gTgqaee4rzzzuO5557jscceQ0QYPHgwzz//PDNmzGDSpEnNZz4Hm9t+//33+eEPf0hqaipbt27l888/b7Mpb+Cw5rzfeecd+vbty7Jly8jMzCQSidCnTx+WL19OZmbmCazkL7QrERhjIsBT0T+llGL69OnMnj27ORG8+uqrLFy4kFmzZpGUlMSBAwcYM2YMkydPPuJ7dJ966im8Xi9btmxh/fr1DBs2rLnfT3/6U9LS0giHw0yYMIH169cza9YsHn/8cRYvXkxGRkarca1evZpnnnmGFStWYIxh9OjRjBs3jtTUVLZt28ZLL73EH//4R6677jpee+21I/7YbOrUqdx+u3UL9MEHH+TPf/4z9957L7NmzWLcuHHMnz+fcDhMfX09mzZt4tFHH2XZsmVkZGQ0t3V0NJ9++ikbN25sbqH10Ka8r7nmGiKRyGHNedtsNm688UZeeOEFZs+ezaJFixgyZMiXTgLQ/t8R9AZ+BgwAPAe7G2N6fekIlFJfzjGO3DtKQUEBZWVl7Nu3j/LyclJTU8nKyuL+++9nyZIl2Gw29u7dS2lpKVlZWW2OY8mSJcyaNQuAwYMHM3jw4OZ+r776KnPnziUUCrF//342b97cqv+hPnx1XI0AACAASURBVPzwQ66++urmVkunTp3K0qVLmTx5Mvn5+QwdOhSwfnVcWFh4xPFs3LiRBx98kOrqaurr67n00ksBeO+995qbs7bb7SQnJ/Pcc88xbdq05qR0sBnsoxk1alRzEoDDm/Letm0b5eXlbTbnfeuttzJlyhRmz57N008/fdIa1GvvpaFngB8DvwIuwmp3SBugUyrGTZs2jXnz5lFSUsL06dN54YUXKC8vZ/Xq1TidTvLy8g5rXro9du3axWOPPcbKlStJTU1lxowZJzSeg9xud/Nnu93e6hLUoWbMmMHrr7/OkCFDePbZZ3n//fePe3oOh4NIJAJAJBKhqampuV/L5rXbasr7aPOZm5tL165dee+99/jkk0944YUXjju2trS3Mo8zxryL1UjdbmPMQ8AVJyUCpdQZa/r06bz88svMmzePadOmUVNTQ5cuXXA6nSxevJjdu3cfdfgLL7ywucXQjRs3sn79egBqa2uJj48nOTmZ0tJS3nrrreZhEhMTqaurO2xcY8eO5fXXX6exsZGGhgbmz5/P2LFjj3ue6urq6NatG8FgsFVFO2HCBJ56yro6Hg6Hqamp4Wtf+xp/+9vfqKioAL5oBjsvL6+5mYsFCxY0v0jnUG015Q0wZsyYNpvzBuvex4033tjqxT1fVnsTQSDaBPU2EblHRK4GEk5KBEqpM9bAgQOpq6sjJyeHbt26ccMNN7Bq1SoGDRrEc889R79+/Y46/F133UV9fT39+/fnRz/6EcOHDwdgyJAhFBQU0K9fP775zW9y/vnnNw9zxx13cNlll3HRRRe1GtewYcOYMWMGo0aNYvTo0dx2220UFBQc9zz95Cc/YfTo0Zx//vmt4v/Nb37D4sWLGTRoEMOHD2fz5s0MHDiQH/zgB4wbN44hQ4bwne98B4Dbb7+dDz74gCFDhrB8+fJWZwEttdWUN3DE5rwBJk+eTH19/Ul9z0J7m6EeCWwBUoCfAEnAL4wxH5+0SNpJm6FWSpuhjmWrVq3i/vvvZ+nSpUcsc9KboY7+eGy6MabeGFNsjJlpjLmmPUlARC4Tkc9EZLuIzDlCmetEZLOIbBKRF9sqo5RSynqRzzXXXMPPfvazkzreY94sNsaEReSC4x1xNIE8CVwMFAMrRWSBMWZzizK9ge8D5xtjqkSky/FORymlTsTdd9/NRx991Krbfffdd1q/2nLOnDnMmdPmMfWX0t6nhtaIyAKst5M1HOxojPn7UYYZBWw3xuwEEJGXgSnA5hZlbgeejLZdhDGm7DhiV0qpE9byHcqxrr2JwANUAF9r0c0AR0sEOUBRi+/FwOhDyvQBEJGPADvwkDHmsKYrROQO4A6AHj16tDNkpZRS7dHeXxZ31LmSA+iN9Yaz7sASERnUsqXT6PTnAnPBulncQbEopVRMau8vi5/BOgNoxRhz61EG2wvktvjePdqtpWJghTEmCOwSkc+xEsPK9sSllFLqy2vv7wj+Cfwr+vcu1uOj9ccYZiXQW0TyRcQFXA8sOKTM60TfdywiGViXina2MyalVCc62Ky0OvO199LQay2/i8hLwIfHGCYkIvcAC7Gu/z9tjNkkIo8Aq4wxC6L9LhGRzUAY+J4xpuIE5kMppdQJOtH2gnoDx3zU0xjzpjGmjzHmLGPMT6PdfhRNAhjLd4wxA4wxg4wxL59gPEqpTmKM4Xvf+x7nnHMOgwYN4pVXXgFg//79XHjhhQwdOpRzzjmHpUuXEg6HmTFjRnPZX/3qV50cvYL23yOoo/U9ghKsdxQopTrZ/3zyP2yt3HpSx9kvrR//Nap9u/jf//531q5dy7p16zhw4AAjR45sbkPo0ksv5Qc/+AHhcJjGxkbWrl3L3r172bhxI4C+Wew00d5LQ4kdHYhS6sz04Ycf8o1vfAO73U7Xrl0ZN24cK1euZOTIkdx6660Eg0Guuuoqhg4dSq9evdi5cyf33nsvV1xxBZdccklnh69o/xnB1cB7xpia6PcUYLwx5vWODE4pdWztPXI/1S688EKWLFnCv/71L2bMmMF3vvMdbr75ZtatW8fChQv5wx/+wKuvvtr8RjHVedp7j+DHB5MAQPQ5/x93TEhKqTPJ2LFjeeWVVwiHw5SXl7NkyRJGjRrF7t276dq1K7fffju33XYbn376KQcOHCASiXDNNdfw6KOP8umnn3Z2+Ir2/7K4rYTR3mGVUl9hV199NcuXL2fIkCGICP/7v/9LVlYWf/nLX/jFL36B0+kkISGB5557jr179zJz5szml7ac7MbT1IlpbzPUTwPVWI3IAdwNpBljZnRcaG3TZqiV0mao1dGd9Gaoo+4FmoBXgJcBP1YyUEopdYZr71NDDcDJb/tUKaVUp2vXGYGIvBN9Uujg91QRWdhxYSmllDpV2ntpKKNli6DR9wfoS2SUUuoroL2JICIizS8CEJE82miNVCml1JmnvY+A/gD4UEQ+AAQYS/RFMUoppc5s7b1Z/LaIjMCq/NdgNR/t68jAlFJKnRrtvVl8G9Z7CP4D+C7wPPBQx4WllPqqOfj+gn379nHttde2WWb8+PEc63dCv/71r2lsbGz+fvnll5/UxutmzJjBvHnzTtr4zgTtvUdwHzAS2G2MuQgowPqBmVJKHZfs7OwvVdEemgjefPNNUlJSjjKEOpb23iPwG2P8IoKIuI0xW0Wkb4dGppRql5L//m8CW05uM9Tu/v3IeuCBo5aZM2cOubm53H239dvShx56CIfDweLFi6mqqiIYDPLoo48yZcqUVsMVFhYyadIkNm7ciM/nY+bMmaxbt45+/frh831xxfmuu+5i5cqV+Hw+rr32Wh5++GGeeOIJ9u3bx0UXXURGRgaLFy8mLy+PVatWkZGRweOPP97ciN1tt93G7NmzKSwsZOLEiVxwwQUsW7aMnJwc3njjDeLi4o65HN59912++93vEgqFGDlyJE899RRut5s5c+awYMECHA4Hl1xyCY899hh/+9vfePjhh7Hb7SQnJ7NkyZLjXeydpr2JoDj6O4LXgXdEpArY3XFhKaVOd9OnT2f27NnNieDVV19l4cKFzJo1i6SkJA4cOMCYMWOYPHkyItLmOJ566im8Xi9btmxh/fr1DBs2rLnfT3/6U9LS0giHw0yYMIH169cza9YsHn/8cRYvXkxGRkarca1evZpnnnmGFStWYIxh9OjRjBs3jtTUVLZt28ZLL73EH//4R6677jpee+01brzxxqPOn9/vZ8aMGbz77rv06dOHm2++maeeeoqbbrqJ+fPns3XrVkSk+bLUI488wsKFC8nJyTnj3rPQ3pvFV0c/PiQii4Fk4O0Oi0op1W7HOnLvKAUFBZSVlbFv3z7Ky8tJTU0lKyuL+++/nyVLlmCz2di7dy+lpaVkZWW1OY4lS5Ywa9YsAAYPHszgwYOb+7366qvMnTuXUCjE/v372bx5c6v+h/rwww+5+uqriY+PB2Dq1KksXbqUyZMnk5+fz9ChQwEYPnw4hYWFx5y/zz77jPz8fPr06QPALbfcwpNPPsk999yDx+PhW9/6FpMmTWLSpEkAnH/++cyYMYPrrruOqVOnHnsBnkaOuwVRY8wHHRGIUurMM23aNObNm0dJSQnTp0/nhRdeoLy8nNWrV+N0OsnLy8Pv9x/3eHft2sVjjz3GypUrSU1NZcaMGSc0noPcbnfzZ7vd3uoS1PFyOBx88sknvPvuu8ybN4/f/e53vPfee/zhD39gxYoV/Otf/2L48OGsXr2a9PT0E57OqXSi7yxWSimmT5/Oyy+/zLx585g2bRo1NTV06dIFp9PJ4sWL2b376FeQD77SEmDjxo2sX78egNraWuLj40lOTqa0tJS33nqreZjExETq6uoOG9fYsWN5/fXXaWxspKGhgfnz5zN27NgTnre+fftSWFjI9u3bAXj++ecZN24c9fX11NTUcPnll/OrX/2KdevWAbBjxw5Gjx7NI488QmZmJkVFRSc87VNN3ymglDphAwcOpK6ujpycHLp168YNN9zAlVdeyaBBgxgxYgT9+vU76vB33XUXM2fOpH///vTv35/hw4cDMGTIEAoKCujXrx+5ubmcf/75zcPccccdXHbZZWRnZ7N48eLm7sOGDWPGjBmMGjUKsG4WFxQUtOsyUFs8Hg/PPPMM06ZNa75ZfOedd1JZWcmUKVPw+/0YY3j88ccB+N73vse2bdswxjBhwgSGDBlyQtPtDO16H8HpRN9HoJS+j0AdXUe9j0AppdRXlF4aUkrFpLvvvpuPPvqoVbf77ruPmTNndlJEnUcTgVJnKGPMEZ/PV8f25JNPHrvQGehELvfrpSGlzkAej4eKiooT2unVV5cxhoqKCjwez3ENp2cESp2BunfvTnFxMeXl5Z0dijrNeDweunfvflzDaCJQ6gzkdDrJz8/v7DDUV0SHXhoSkctE5DMR2S4ic9roP0NEykVkbfTvto6MRyml1OE67IxAROzAk8DFQDGwUkQWGGM2H1L0FWPMPR0Vh1JKqaPryDOCUcB2Y8xOY0wT8DIw5RjDKKWUOsU6MhHkAC0b2yiOdjvUNSKyXkTmiUhuWyMSkTtEZJWIrNKbY0opdXJ19uOj/wDyjDGDgXeAv7RVyBgz1xgzwhgzIjMz85QGqJRSX3UdmQj2Ai2P8LtHuzUzxlQYYwLRr38ChndgPEoppdrQkYlgJdBbRPJFxAVcDyxoWUBEurX4OhnY0oHxKKWUakOHPTVkjAmJyD3AQsAOPG2M2SQijwCrjDELgFkiMhkIAZXAjI6KRymlVNu0GWqllIoB2gy1UkqpI9JEoJRSMU4TgVJKxThNBEopFeM0ESilVIzTRKCUUjFOE4FSSsU4TQRKKRXjNBEopVSM00SglFIxThOBUkrFOE0ESikV4zQRKKVUjNNEoJRSMU4TgVJKxThNBEopFeM0ESilVIzTRKCUUjFOE4FSSsU4TQRKKRXjNBEopVSM00SglFIxThOBUkrFOE0ESikV4zQRKKVUjNNEoJRSMU4TgVJKxThNBEopFeM6NBGIyGUi8pmIbBeROUcpd42IGBEZ0ZHxKKWUOlyHJQIRsQNPAhOBAcA3RGRAG+USgfuAFR0Vi1JKqSPryDOCUcB2Y8xOY0wT8DIwpY1yPwH+B/B3YCxKKaWOoCMTQQ5Q1OJ7cbRbMxEZBuQaY/51tBGJyB0iskpEVpWXl5/8SJVSKoZ12s1iEbEBjwP/cayyxpi5xpgRxpgRmZmZHR+cUkrFkI5MBHuB3Bbfu0e7HZQInAO8LyKFwBhgQUfdMDbBII1r1nTEqJVS6ozWkYlgJdBbRPJFxAVcDyw42NMYU2OMyTDG5Blj8oCPgcnGmFUdEUz573/P7ptvoW7x4o4YvVJKnbE6LBEYY0LAPcBCYAvwqjFmk4g8IiKTO2q6R1IzdTzVuSkUz7qP+iVLTvXklVLqtNWh9wiMMW8aY/oYY84yxvw02u1HxpgFbZQd31FnAwDLatdy/+RKijKFPXffTf2HH3XUpJRS6owSM78svmXgLfz2qmf407dy2J0aYtddd9C4a2dnh6WUUp0uZhIBwMiskTx//Xx2//gmQkRY/uO7OzskpZTqdDGVCADcdjd3TniAXVcMJvuTQpa8/afODkkppTpVzCWCgy5/4P+oS3RQ/ctfs6dmT2eHo5RSnSZmE4EnKYXMe++hd1GYPz15O03hps4OSSmlOkXMJgKAvG9+i2CPLMb9Yw8vb/xrZ4ejlFKdIqYTgTgc9PrBQ2RXQfEffku1v7qzQ1JKqVMuphMBQMK4ccjXx3LlB35efPPnnR2OUkqdcjGfCADOfuTnhOLd9PjtAnZX7urscJRS6pTSRAA40tLI/MH3OWu/YfEv7u/scJRS6pTSRBCVM+U6ykeeRcGCz/joxV92djhKKXXKaCKIEhGG/eIPVHaNI+2RP7HhthsJlpZ2dlhKKdXhNBG0kJDVnSFvLOTNiRlEPl7N9okT2f/DH1G/9ENMMNjZ4Z2xTFMTNf/4J+FqfSrrqyLi81G/ZAkmHO7sUNRJIMaYzo7huIwYMcKsWtVhjZQCUNJQwv1//SaXLapk5HZBfH5sSUkkTZxIyjVT8QwahIgAYIxp/qwOFywrY+/s+/F9+inO7t3p/uTv8PTte8zhmoqKsHk8OPSNdKedYFkZxd++G//GjXhHjSL7sV/g7NLlpIzbNDVhAJvLdVLGdzwiPh/i8Xxl92cRWW2MafPFX5oIjmBXzS7ufOdOymv2ckvDUK7YlUpo8YcYvx/XWWdhT0wkWFZKqPwA9vh4nD164MrNxdkjF1duD1y53bElJUM4hAmHiTQ0Eq6uso6KbTZcPXriys/DkZ6OCQSI+P0ggj01tXlD9G3cRPUrL9O4chXe0aNJuuxSvCNHEiwpxb9hPYEdO/EM6I931GjsCfEARBobCezYibhdODIzsScn07RzJw3LltO48hPsKakkfO0i4s89F7Hb8W/dim/NWuzJSSROnNhqB4z4/fjWrKFx9af4Pl1NuLaOpMsuJenKyTi7Hr7jm0iEcGUl2O3YXC78W7ZQfP/9ROobyLjzTqpeeIFwXR3dfvITvCNHECwuJrhvPzZvHI6uWTgy0mlYtpzqefPwffopiOAdM5rkSZPwjhiBPTkZW2IiYrd/qXUbqqykbuFCGpYtw4QjiN2OuN3EDToH75gxuHv3JtLoI7BlM/7PPgcBe2IitsREXD3zcOX1RGzHdzJtgkECu3bRsGwZDR8tI1RainfEcLznnkv8qFHYk5O/1DwdddrGENq3D/+2bQS2bUNsNjz9++Pu3x/j81G/ZCn1S5diQkFSp19PwvhxR5w//5YtFN31bcK1taTd8E0q//oCNq+XnF/8L/HnnffFNCMRGj76iNq33sbZPYeECy7AM3AgYrdjjME0NiJxcc3TCVdXU/n8X6n8618xfj9xwwqIH3Mu3hHDcffthz0hHmMMTdu3U/f++4QPVOAdOQLvyJHHvewijY2Iw4G4XJhgkPoPPqB63mvUL1mCMyuLxEsvJenSS3D364fN4zn28o1E8G/cSLiuDk///jjS0todS7CsjKoXX6Rh6Yd4BvQn/txziRs2jIjPR6i8nHBNDa7cXNxnnYU4ncc1n4fSRHCCfCEfz256lqc3PE3ERBibOoIJ2zz0WrkXr8OLKysLR2YmkfoGgkV7aNpTRHD/fvgSp8u2hARceXmYSJjA5i1IXBzeggIa1661dh6n8/DLVE4nceecQ7iqiqbdu6HlOrXZIBKxiuXmEq6sJNLQgEQ3cOP3Nxe1Z2aQduNNuPLyqFu4kLr338c0NoII7n79EJcT/7r1YLMRV1CAIz0dW2ICiNC0fQeBbduINDS0Dq1HD7r/9rd4+vYhVF5O8ez78a1efdRl4MrPJ+Xaa4g0+qj55z8I7m7RFpQI9uRkHJkZ2DMysHnjraPIJquJEHtSIrakJGzeeGs5RMKYcAQTDkEoTKisjIYVKyAcxpmbiy0hAUJBwg0NhPbtb14HkYaG1sux5TryenEP6I87vxfO7G44unWzloXXiy0+nlBpKY2rVtO4ejVNe/YQqa9vtZxdvXrhzMpqXqfYbHgGnUPC+efj7tePwPbt+NdvoGn3blw9e+IZ0B93n77YU1KwxccjToeVwNeuxb9hI5HGRohEMMZgi4/HkZqCLTnZ2i737iW4fz/G5zvqMndmZ2MiEUIlJbjy8ki85BJMIEC4tpZIfT0Rvx/j9+PbtAl7UhK5T/0eT//+BLZto3j2/TTt2IEzJwfPoEG4crtT+/ZCgkVF1rKsr7eWW3Iy4nISrq6BYBBxuXDm5uLMzsa3ejWRxkYSvj4BV04ODR+vIPDZZ83r3JWXhwkGCRYXW51cLmudi+DskYvYHSCCzePBffZZuPv0xdUrH5s3HnE5MYEADcs/pn7pEgKbt1jjcDrBbsf4/TgyM0m6fCJNhbupX7YMovuYeL04UlLA6YBQGBOJYE9OxtWjB64euYTKy6lfspRwVVXzsnRkZeHq2RPxuLG53Jiwtd2FysqI+P24evbE3SsfEzHUvf02JhQibsgQAjt2EKmra3P9iNOJu3dv0u+6k6SLLz7qujwSTQRfUklDCX/e8Gc+3v8xhbWFgNWK6cD0gRR0KSA9Lt06ysHgFTdda4S0iibiw3a8nkTiXAnY4jwEEtzUe21IKExyWSORomJClZXYPHFInAdCIZoKd9NUWEiksZGkSZNInjIZe2Ji9JrsUhpXrcKVn0fcoMG4e+Xj27CR+qVL8K1ajaNLJu6+/XD36Q2hEKHyckIHKnD2yCX+3PNwdc/BNDXRsHIl9e9/AALeggLihg4lsHMnlU8/Q8NH1gt77KmpJF58MYlfn0BcQQH2xEQAArt2UbNgAY0fryBcV0ukrh4TCuHOz8fdty+uvDzAOsXHbiNl6lTsSUnNy9I0NVH997+DMTi7d8eZnU3E5ydUWkKwtBRP797EjRjR6tKbf+MmAju2E6mpIVxTQ6iqivCBA4TKD1in8y4X4nKBMUTqagnX1lmVo81mjcdmQxwOcNixx8eTMH48SVdcgbtv31aXAYL79tGw4hN8a9fi6JKJZ+BAPP0HIE4HkdpawjU1BLbvwL9pE/7Nm2kqKiJcUdH2RuNw4Bk4AE+fPtgSk7AlxOPsmkX8uWNwZmc3Lwvfhg00fLSMho8+wrdhg5W0RXD16oUrL4+m3YU07dzVnMxbsiUkEDd4EPaUFBDryDrS0EC4yjrztMXH48zJwZmdjSs/D3efPrh798aEQgS2bMG/ZQvY7CRcOBZXr14QClH7739T+exf8G/YgC0+HltSEvaEeMQTh7hdOLtm0eW//rPVpaBIQwNVf/sbvrXr8G/YQHDvXrwjRpDyjetJuvhiwvX1NHy0jMZPVljbVkoKtqQkwtXVBPdYB1DuPn1Iv/02PH36NI83VFGBb/16/Fu24N+0GYCECy8kYdyF2NPS8K9fT8OKFTTt2IGJGGv919cT2LaNUFnZ4evEbieuYCjxY85FHHYrwQWaiD/3XBIuHGttI0C4tpb6JUsJ7t1rLcuqyuiZow1s9uYDrqbiYuwJCcSPvYCEsRfiyEjHv2Ur/s2breQbCGACARDB0aULji5dELeL4O7dBHbuIlJXR/JVV5F2y824evTAhEL4N2/Gt2ED9sREHBkZ2JKSaSosxL9lM4EtW0i75RYSxo1re5s7Bk0EJ1GFr4I1ZWua/7ZUbCFkQkcdxnZwJzWRVt26eruS4k7BF/LRGGokFAnhsDlw2924bC5sNhsOcSAihCIhQpEQYRPGZXcRZ4/D7XBjExuCWP9Fmj8fTEwGg9PmxGP34HF4cNqc2MWOw+bALnZsNht2sSMIERPBW3QAd10TvgE9cbnjmqcvCGETpiZQQ21TLb6QD6fNicPmwGk7/JRVRLCLnWR3MmmeNFLcKRgMwUiQYDhIha+CMl8ZBxoP4LQ7SXIlkeROQhCawk0EwgEMBrvYsYudCBGC4SDBSBCX3UVXb1ey4rNw2Bzsr9/P3vq9VAeqCZtw830br8OL1+nF6/AS54gjzhGH2+4mbMLN5dI8aWR6M0n1pFLXVMcB3wEq/ZU0hZual7cNGw6bA4fN0WrZBiNBgo31UFaBs96PO2BwB8JIchL07018YhpNkSb21e9jf8N+fCEfqe5UUj2pJDgTCJkW69TmwuMLE7+vmobuqTR5HBgM8c54Eo2bxH01BKqr8NdX4W+opT47hfruqUQEvE4vSa4kEl2J2MRmbSsmBG3s2gZDKBIiEA5Yy/j/t3dvMZKUVQDH/6equnp6em47uy7rLLALclE0ctGQVdQQ8AHQCA9rvCASQ+ILiWBMFILG6JuJETUhiAF1UYIGBCU8GGUlGB64i4iAchF2l91xl51Lz/S1LseH+rp2dnYH9jKzDV3nl0ymq7q66vvqVNWp7+vqKlVCPyT0QwIvQFVJNSVQj1WDq1k1sIrAC9g+t51ttW1MtadYW1nLxNAEqyurme/MM92eZq4zR+iF2TpOPbywnC8z9EMGggEG/AFijekkHTpJB0XxJNv+KkEl3wZSTam1a8x2ZmlE2X4RpVG+/4gIgQR5bEt+ab95VoIKlfkIf+ceWo0azUaNVtKmftoE7UpAnMaU/XJWpmCAsl/O97lG3GC2PctcZw7P86gGVaqlKorSjrN1lpISSICvwmh5lBPHNjJazrqnap0ar86+yhvNN/LtrLvvxml2nBgOhxkOhxn0K0RufcRpTMkrUfJLlLwSURrRTtpEScR4ZZx1g+tYU1mD7x15t6glghXUTtq04lZ+QJ6P5tnb3Mue5h5m2jP5Bq2qjJXHGC2PkmjCzvmd7JzfyWxnNj9Q7bcBpBFJmpBqSqJJfsD1xc934mbcRMl23O7BKdWUVNP84C1IPs9m3MwPEnEaZ/N2y+julJ54+cZ7MJ54DIfDVIIKSZrkO+lCiqKqJJrQTtpLrrtKUGFNZQ1JmjDbmaUe1fNllP3sQNKtvy8+Ja9E6Ic04ybNuHnAvMYHxrPkJh6ppjTiBvWofsC0vTASjlAtVZlpz7wtynOkAi9YctsosrHyGJ54TLWmVmwZgQTcsOkGNp+2+Yg+/2aJIDiqkpn8bKJrKBxiXXVdD0u0PJI0oZN2iNKI7smCLz6DpcG8hXMomnGT6dY00+3prCUiASW/xPjAOEOlof27ZtIIQQi8N98sVZVap8ZkfZI4jZkYmmCsPLbk1R6ppnnCbiftrJXhzqymmlPsbu5mujXNcDjMmsoaxgfGqQSVPKl0z6IXJ7ySV9ov/rHGREmUtfCiBvW4ji8+E0MTVEvV/HONqEEjbhDIvlZGN1l3W4WBF+DhMR/NM9eZox7VqZaqjJSzM//uSUF3HdfaNWpRDcgOGN2yH0zgBdlZup9dIdNtgcVpnLUOReikHWZaM3nr6IThEzhx5ERGwhGm29Psmt/F3tZeRsIRRsujDIfDxGlMI27Q9aOpHAAABoJJREFUivd9H6Jovk5acWtfi9cP8/eTNKERN6h1atTaNXzxGSmPMBqOUillJ0glr5THQlXzZTXjJp2kQ+iH+TStuEUzbtJO2lRL1fyvu9zAC7IyJc18m2jHbdppm2qwbx2naUo9rlOP6vnJSeiHeGQnGlEaMdWaYvvcdl6rvUaqKRtGNrBxZCNrq2v3i2/3RE5V85g24gaht681FqVR3jrottJ88ZlqTTFZn2SyPsnpq976irsjYS0CY4wpgDdrEdgPyowxpuAsERhjTMFZIjDGmIKzRGCMMQVnicAYYwrOEoExxhScJQJjjCk4SwTGGFNw77gflInIHuC1I/z4GuCNZSzOO0UR613EOkMx613EOsPh13uDqh70AR/vuERwNETkiaV+WdfPiljvItYZilnvItYZlrfe1jVkjDEFZ4nAGGMKrmiJ4Oe9LkCPFLHeRawzFLPeRawzLGO9C/UdgTHGmAMVrUVgjDFmEUsExhhTcIVJBCJykYj8W0ReEpHrel2elSAiJ4jIgyLynIj8S0SucePHReQvIvKi+7+q12VdbiLii8jfReR+N3ySiDzq4v07EQl7XcblJiJjInK3iLwgIs+LyEcKEuuvu+37WRG5U0QG+i3eIvILEdktIs8uGHfQ2Ermp67uz4jIOYe7vEIkAhHxgZuAi4EzgC+IyBm9LdWKiIFvqOoZwCbgalfP64CtqnoqsNUN95trgOcXDP8AuFFVTwGmgat6UqqV9RPgT6r6XuBMsvr3daxFZD3wNeDDqvoBwAc+T//F+1fARYvGLRXbi4FT3d9XgZsPd2GFSATAucBLqvqKqnaA3wKX9rhMy05Vd6nqU+71HNmBYT1ZXbe4ybYAl/WmhCtDRI4HPgXc6oYFuAC4203Sj3UeBT4B3Aagqh1VnaHPY+0EQEVEAmAQ2EWfxVtV/wZMLRq9VGwvBW7XzCPAmIi8+3CWV5REsB7YvmB4hxvXt0RkI3A28ChwnKrucm9NAsf1qFgr5cfAN4HUDa8GZlQ1dsP9GO+TgD3AL12X2K0iUqXPY62qrwM/BLaRJYBZ4En6P96wdGyP+vhWlERQKCIyBPweuFZVawvf0+x64b65ZlhEPg3sVtUne12WYywAzgFuVtWzgTqLuoH6LdYArl/8UrJEOAFUObALpe8td2yLkgheB05YMHy8G9d3RKRElgTuUNV73Oj/dZuK7v/uXpVvBZwHfEZEXiXr8ruArO98zHUdQH/GewewQ1UfdcN3kyWGfo41wCeB/6rqHlWNgHvItoF+jzcsHdujPr4VJRE8DpzqriwIyb5cuq/HZVp2rm/8NuB5Vf3RgrfuA650r68E/nisy7ZSVPV6VT1eVTeSxfWvqno58CCw2U3WV3UGUNVJYLuInO5GXQg8Rx/H2tkGbBKRQbe9d+vd1/F2lortfcCX3dVDm4DZBV1Ih0ZVC/EHXAL8B3gZuKHX5VmhOn6MrLn4DPC0+7uErM98K/Ai8AAw3uuyrlD9zwfud69PBh4DXgLuAsq9Lt8K1Pcs4AkX7z8Aq4oQa+B7wAvAs8CvgXK/xRu4k+w7kIis9XfVUrEFhOyqyJeBf5JdUXVYy7NbTBhjTMEVpWvIGGPMEiwRGGNMwVkiMMaYgrNEYIwxBWeJwBhjCs4SgTHHkIic371DqjFvF5YIjDGm4CwRGHMQIvIlEXlMRJ4WkVvc8w7mReRGdy/8rSLyLjftWSLyiLsX/L0L7hN/iog8ICL/EJGnROQ9bvZDC54jcIf7hawxPWOJwJhFROR9wOeA81T1LCABLie7wdkTqvp+4CHgu+4jtwPfUtUPkv2yszv+DuAmVT0T+CjZL0UhuyvstWTPxjiZ7F45xvRM8NaTGFM4FwIfAh53J+sVsht8pcDv3DS/Ae5xzwUYU9WH3PgtwF0iMgysV9V7AVS1BeDm95iq7nDDTwMbgYdXvlrGHJwlAmMOJMAWVb1+v5Ei31k03ZHen6W94HWC7Yemx6xryJgDbQU2i8hayJ8Vu4Fsf+ne4fKLwMOqOgtMi8jH3fgrgIc0e0LcDhG5zM2jLCKDx7QWxhwiOxMxZhFVfU5Evg38WUQ8sjtAXk328Jdz3Xu7yb5HgOyWwD9zB/pXgK+48VcAt4jI9908PnsMq2HMIbO7jxpziERkXlWHel0OY5abdQ0ZY0zBWYvAGGMKzloExhhTcJYIjDGm4CwRGGNMwVkiMMaYgrNEYIwxBfd/hwsFSji08nkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVcpg7N88Hmz"
      },
      "source": [
        "model.save('/content/drive/MyDrive/vatIAtech/DSTI/ANN/practical/churn_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFE1REJo8Y3x"
      },
      "source": [
        "my_trained_model = keras.models.load_model('/content/drive/MyDrive/vatIAtech/DSTI/ANN/practical/churn_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}